[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "[SER 2025] Modern Causal Mediation Analysis",
    "section": "",
    "text": "Welcome to SER 2025!\nThis open source, reproducible vignette accompanies a half-day workshop on modern methods for causal mediation analysis, offered at the SER 2025 annual meeting.",
    "crumbs": [
      "Welcome to SER 2025!"
    ]
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "[SER 2025] Modern Causal Mediation Analysis",
    "section": "About this workshop",
    "text": "About this workshop\nCausal mediation analysis can provide a mechanistic understanding of how an exposure impacts an outcome, a central goal in epidemiology and health sciences. However, rapid methodologic developments coupled with few formal courses presents challenges to implementation. Beginning with an overview of classical direct and indirect effects, this workshop will present recent advances that overcome limitations of previous methods, allowing for: (i) continuous exposures, (ii) multiple, non-independent mediators, and (iii) effects identifiable in the presence of intermediate confounders affected by exposure. Emphasis will be placed on flexible, stochastic and interventional direct and indirect effects, highlighting how these may be applied to answer substantive epidemiological questions from real-world studies. Multiply robust, nonparametric estimators of these causal effects, and free and open source R packages (crumble) for their application, will be introduced.\nTo aid translation to real-world data analysis, this workshop will incorporate hands-on R programming exercises to allow participants practice in implementing the statistical tools presented. It is recommended that participants have working knowledge of the basic notions of causal inference, including counterfactuals and identification (linking the causal effect to a parameter estimable from the observed data distribution). Familiarity with the R programming language is also recommended.",
    "crumbs": [
      "Welcome to SER 2025!"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "[SER 2025] Modern Causal Mediation Analysis",
    "section": "Tentative schedule",
    "text": "Tentative schedule\n\n08:30A-08:45A: Introductions + mediation set-up \n\n08:45A-9:15A: Controlled direct effects, natural direct/indirect effects, interventional direct/indirect effects   \n\n9:15A-9:25A: Choosing an estimand in real-world examples \n\n9:25A-10:00A: What is the EIF?! \n\n10:00A-10:30A: Break + discussion\n10:30A-11:05A: Using the EIF for estimating the natural direct effect \n\n11:05A-12:00P: Example walkthrough with R packages for effect estimation \n\n12:00A-12:30P: Wrap-up\n\nNOTE: All times listed in Eastern Daylight Time (EDT).",
    "crumbs": [
      "Welcome to SER 2025!"
    ]
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "[SER 2025] Modern Causal Mediation Analysis",
    "section": "About the instructors",
    "text": "About the instructors\nIván Díaz\nI am an Associate Professor of Biostatistics in the Department of Population Health at the NYU Grossman School of Medicine. My research focuses on the development of non-parametric statistical methods for causal inference from observational and randomized studies with complex datasets, using machine learning. This includes but is not limited to mediation analysis, methods for continuous exposures, longitudinal data including survival analysis, and efficiency guarantees with covariate adjustment in randomized trials. I am also interested in general semi-parametric theory, machine learning, and high-dimensional data.\nNima Hejazi\nI am an Assistant Professor of Biostatistics at the Harvard Chan School of Public Health, where my research program explores how advances in causal inference, machine learning, and computational statistics help catalyze discovery in the biomedical and health sciences. I develop model-agnostic statistical methods using ideas from causal inference, semi-parametric statistics, and causal machine learning. Areas of recent emphasis have included causal mediation analysis, causal inference for continuous exposures, efficient inference under auxiliary- or outcome-dependent sampling designs, and sieve methods for causal machine learning. My methods research is directly tied to applied science problems from studies of investigational agents to treat or prevent infectious diseases, chronic diseases, and cancer. I am also interested in open-source software and high-performance computing for statistics and in reproducible statistical data science.\nKara Rudolph\nI am an Associate Professor of Epidemiology at the Columbia Mailman School of Public Health. My research interests are in developing and applying causal inference methods to understand social and contextual influences on mental health, substance use, and violence in disadvantaged, urban areas of the United States. My current work focuses on developing methods for transportability and mediation, and subsequently applying those methods to understand how aspects of the school and peer environments mediate relationships between neighborhood factors and adolescent drug use across populations. More generally, my work on generalizing/transporting findings from study samples to target populations and identifying subpopulations most likely to benefit from interventions contributes to efforts to optimally target available policy and program resources.\nNick Williams\nI am a Senior Data Analyst in Columbia University’s Mailman School of Public Health, Department of Epidemiology, and an incoming PhD student in Biostatistics at the University of California, Berkeley. My interests are in the development of statistical computing tools for novel causal inference methods. I am the author and maintainer of several R packages for conducting causal analyses in R.",
    "crumbs": [
      "Welcome to SER 2025!"
    ]
  },
  {
    "objectID": "index.html#repro",
    "href": "index.html#repro",
    "title": "[SER 2025] Modern Causal Mediation Analysis",
    "section": "Reproducibility note",
    "text": "Reproducibility note\nThese workshop materials were written using the Quarto, an open-source, cross-platform technical publishing system built on RMarkdown, and the complete source is available on GitHub. This version of the book was built with R version 4.5.0 (2025-04-11), pandoc version 3.6.3, and quarto version 1.7.31. See the renv.lock file in the source repository for an up-to-date list of the packages used.",
    "crumbs": [
      "Welcome to SER 2025!"
    ]
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "[SER 2025] Modern Causal Mediation Analysis",
    "section": "Setup instructions",
    "text": "Setup instructions\nR and RStudio\nR and RStudio are separate downloads and installations. R is the underlying statistical computing environment. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio.\nVirtual environment setup with renv\n\nThese instructions are intended to help with setting up the included renv virtual environment, which ensures all participants are using the same exact set of R packages (and package versions). A few important notes to keep in mind:\n\nWhen R is started from the top level of this repository, renv is activated automatically. There is no further action required on your part. If renv is not installed, it will be installed automatically, assuming that you have an active internet connection.\nWhile renv is active, the R session will only have access to the packages (and their dependencies) that are listed in the renv.lock file—that is, you should not expect to have access to any other R packages that may be installed elsewhere on the computing system in use.\nUpon an initial attempt, renv will prompt you to install packages listed in the renv.lock file, by printing a message.\n\nIn any such case, please call renv::status() to review the list of packages missing and to view renv’s recommendations for fixing the issue; usually, renv::restore() will be the next step necessary to install any missing packages. Note that you do not need to manually install the packages via install.packages(), remotes::install_github(), or similar, as renv will attempt do this for you.\nWhile unnecessary for the purposes of this workshop, if you’d like to learn more about the details of how the renv virtual environment system works, the following references may be helpful:\n\nCollaborating with renv\nIntroduction to renv\n\nIn some rare cases, R packages that renv automatically tries to install as part of the renv::restore() process may fail due to missing systems-level dependencies. In such cases, a reference to the missing dependencies and system-specific instructions their installation involving, e.g., Ubuntu Linux’s apt or homebrew for macOS, will usually be displayed.",
    "crumbs": [
      "Welcome to SER 2025!"
    ]
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1  Causal mediation analysis intro",
    "section": "",
    "text": "1.1 Motivating study",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal mediation analysis intro</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#motivating-study",
    "href": "chapters/intro.html#motivating-study",
    "title": "1  Causal mediation analysis intro",
    "section": "",
    "text": "We recently estimated the risk of opioid use disorder and opioid overdose that is due to having a chronic pain condition or a physical disability (total effects).\n\nHaving a chronic pain condition (without disability) more than doubled the risk (3.6% developed OUD in 18 mo).\nHaving a physical disability (without chronic pain) increased risk by more than 1.6 times (2.9% developed OUD).\n\n\nTo what extent are these total risks explained by the pain management treatments that result from these conditions? Which treatments are more risky? Which are less risky?\nWe can to use mediation analysis to explore the pain management mechanisms contributing to these risks.\n\nKey questions:\n\nTo what extent does the effect of having a disability or chronic pain condition at the time of Medicaid enrollment on subsequent OUD risk operate through pain management strategies? Considered as a bundle? And one-by-one? (Rudolph et al. 2025)\n\n\n\n\n\n\nRudolph, Kara E, Shodai Inose, Nicholas T Williams, Katherine L Hoffman, Sarah E Forrest, Rachael K Ross, Floriana Milazzo, et al. 2025. “Mediation of Chronic Pain and Disability on Opioid Use Disorder Risk by Pain Management Practices Among Adult Medicaid Patients, 2016-2019.” American Journal of Epidemiology, kwaf093.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal mediation analysis intro</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#what-is-causal-mediation-analysis",
    "href": "chapters/intro.html#what-is-causal-mediation-analysis",
    "title": "1  Causal mediation analysis intro",
    "section": "\n1.2 What is causal mediation analysis?",
    "text": "1.2 What is causal mediation analysis?\n\nStatistical mediation analyses assess associations between the variables. They can help you establish, for example, if the association between treatment and outcome can be mostly explained by an association between treatment and mediator\nCausal mediation analyses, on the other hand, seek to assess causal relations. For example, they help you establish whether treatment causes the outcome because it causes the mediator. To do this, causal mediation seek to understand how the paths behave under circumstances different from the observed circumstances (e.g., interventions)\n\n\n1.2.1 Why are the causal methods that we will discuss today important?\n\nAssume you are interested in the effect of treatment assignment \\(A\\) (e.g., chronic pain condition vs. neither chronic pain nor physical disability) on an outcome \\(Y\\) (risk of OUD) through mediators \\(M\\) (e.g., opioid prescriptions, co-prescriptions, anti-depressants and anti-inflammatories, physical therapy)\nWe have pre-treatment confounders \\(W\\)\n\nWhen considering particular pain management treatments, there are intermediate confounders, \\(Z\\), of the \\(M \\rightarrow Y\\) relationship that are affected by chronic pain: other co-occurring or upstream pain management treatments\nWe could fit the following models: \\[\\begin{align}\n    \\E(M \\mid A=a, W=w, Z=z) & = \\gamma_0 + \\gamma_1 a + \\gamma_2 w + \\gamma_3 z \\\\\n    \\E(Y \\mid M=m, A=a, W=w, Z=z) & = \\beta_0 + \\beta_1 m + \\beta_2 a + \\beta_3 w + \\beta_4 z\n  \\end{align}\\]\n\nThe product \\(\\gamma_1 \\beta_1\\) has been proposed as a measure of the effect of \\(A\\) on \\(Y\\) through \\(M\\)\n\nCausal interpretation problems with this method: We will see that this parameter cannot be interpreted as a causal effect\n\n1.2.2 R Example:\n\nAssume we have a pre-treatment confounder of \\(Y\\) and \\(M\\), denote it with \\(W\\)\nFor simplicity, assume \\(A\\) is randomized\n\nWe’ll generate a really large sample from a data generating mechanism so that we are not concerned with sampling errors\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nNote that the indirect effect (i.e., the effect through \\(M\\)) in this example is nonzero (there is a pathway \\(A \\rightarrow Z \\rightarrow M \\rightarrow Y\\))\n\nLet’s see what the product of coefficients method would say:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nAmong other things, in this workshop:\n\nWe will provide some understanding for why the above method fails in this example\nWe will study estimators that are robust to misspecification in the above models",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal mediation analysis intro</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#causal-mediation-models",
    "href": "chapters/intro.html#causal-mediation-models",
    "title": "1  Causal mediation analysis intro",
    "section": "\n1.3 Causal mediation models",
    "text": "1.3 Causal mediation models\nIn this workshop we will use directed acyclic graphs. We will focus on the two types of graph:\n\n1.3.1 No intermediate confounders\n\nCode\\dimendef\\prevdepth=0\n\\pgfdeclarelayer{background}\n\\pgfsetlayers{background,main}\n\\usetikzlibrary{arrows,positioning}\n\\tikzset{\n&gt;=stealth',\npunkt/.style={\nrectangle,\nrounded corners,\ndraw=black, very thick,\ntext width=6.5em,\nminimum height=2em,\ntext centered},\npil/.style={\n-&gt;,\nthick,\nshorten &lt;=2pt,\nshorten &gt;=2pt,}\n}\n\\newcommand{\\Vertex}[2]\n{\\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\VertexR}[2]\n{\\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\ArrowR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend right=30] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\ArrowL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend right=-45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\Arrow}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) -- +(#2);\n\\end{pgfonlayer}\n}\n\\begin{tikzpicture}\n  \\Vertex{-4, 0}{W}\n  \\Vertex{0, 0}{M}\n  \\Vertex{-2, 0}{A}\n  \\Vertex{2, 0}{Y}\n  \\Arrow{W}{A}{black}\n  \\Arrow{A}{M}{black}\n  \\Arrow{M}{Y}{black}\n  \\ArrowL{W}{Y}{black}\n  \\ArrowL{A}{Y}{black}\n  \\ArrowL{W}{M}{black}\n\\end{tikzpicture}\n\n\n\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\n\n1.3.2 Intermediate confounders\n\nCode\\dimendef\\prevdepth=0\n\\pgfdeclarelayer{background}\n\\pgfsetlayers{background,main}\n\\usetikzlibrary{arrows,positioning}\n\\tikzset{\n&gt;=stealth',\npunkt/.style={\nrectangle,\nrounded corners,\ndraw=black, very thick,\ntext width=6.5em,\nminimum height=2em,\ntext centered},\npil/.style={\n-&gt;,\nthick,\nshorten &lt;=2pt,\nshorten &gt;=2pt,}\n}\n\\newcommand{\\Vertex}[2]\n{\\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\VertexR}[2]\n{\\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\ArrowR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend right=30] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\ArrowL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend right=-45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\Arrow}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) -- +(#2);\n\\end{pgfonlayer}\n}\n\\begin{tikzpicture}\n  \\Vertex{0, -1}{Z}\n  \\Vertex{-4, 0}{W}\n  \\Vertex{0, 0}{M}\n  \\Vertex{-2, 0}{A}\n  \\Vertex{2, 0}{Y}\n  \\ArrowR{W}{Z}{black}\n  \\Arrow{Z}{M}{black}\n  \\Arrow{W}{A}{black}\n  \\Arrow{A}{M}{black}\n  \\Arrow{M}{Y}{black}\n  \\Arrow{A}{Z}{black}\n  \\Arrow{Z}{Y}{black}\n  \\ArrowL{W}{Y}{black}\n  \\ArrowL{A}{Y}{black}\n  \\ArrowL{W}{M}{black}\n\\end{tikzpicture}\n\n\n\nDirected acyclic graph under intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\nThe above graphs can be interpreted as a non-parametric structural equation model (NPSEM), also known as structural causal model (SCM):\n\\[\\begin{align}\n  W & = f_W(U_W) \\nonumber \\\\\n  A & = f_A(W, U_A) \\nonumber \\\\\n  Z & = f_Z(W, A, U_Z) \\nonumber \\\\\n  M & = f_M(W, A, Z, U_M) \\nonumber \\\\\n  Y & = f_Y(W, A, Z, M, U_Y)\n\\end{align}\\]\n\nHere \\(U=(U_W, U_A, U_Z, U_M, U_Y)\\) is a vector of all unmeasured exogenous factors affecting the system\nThe functions \\(f\\) are assumed fixed but unknown\nWe posit this model as a system of equations that nature uses to generate the data\nTherefore we leave the functions \\(f\\) unspecified (i.e., we do not know the true nature mechanisms)\nSometimes we know something: e.g., if \\(A\\) is randomized we know \\(A=f_A(U_A)\\) where \\(U_A\\) is the flip of a coin (i.e., independent of everything).",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal mediation analysis intro</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#counterfactuals",
    "href": "chapters/intro.html#counterfactuals",
    "title": "1  Causal mediation analysis intro",
    "section": "\n1.4 Counterfactuals",
    "text": "1.4 Counterfactuals\n\nRecall that we are interested in assessing how the pathways would behave under circumstances different from the observed circumstances\nWe operationalize this idea using counterfactual random variables\nCounterfactuals are hypothetical random variables that would have been observed in an alternative world where something had happened, possibly contrary to fact \n\n\n\n1.4.1 We will use the following counterfactual variables:\n\n\n\\(Y_a\\) is a counterfactual variable in a hypothetical world where \\(\\P(A=a)=1\\) with probability one for some value \\(a\\)\n\n\n\\(Y_{a,m}\\) is the counterfactual outcome in a world where \\(\\P(A=a,M=m)=1\\)\n\n\n\\(M_a\\) is the counterfactual variable representing the mediator in a world where \\(\\P(A=a)=1\\).\n\n1.4.2 How are counterfactuals defined?\n\n\nIn the NPSEM framework, counterfactuals are quantities derived from the model.\nOnce you define a change to the causal system, that change needs to be propagated downstream.\n\nExample: modifying the system to make everyone receive XR-NTX yields counterfactual adherence, mediators, and outcomes.\n\n\nTake as example the DAG in Figure 1.2: \\[\\begin{align}\n  A    &= a \\nonumber \\\\\n  Z_a  &= f_Z(W, a, U_Z) \\nonumber \\\\\n  M_a  &= f_M(W, a, Z_a, U_M) \\nonumber \\\\\n  Y_a  &= f_Y(W, a, Z_a, M_a, U_Y)\n\\end{align}\\]\n\nWe will also be interested in joint changes to the system: \\[\\begin{align}\n  A        &= a \\nonumber \\\\\n  Z_a      &= f_Z(W, a, U_Z) \\nonumber \\\\\n  M        &= m \\nonumber \\\\\n  Y_{a,m}  &= f_Y(W, a, Z_a, m, U_Y)\n\\end{align}\\]\n\nAnd, perhaps more importantly, we will use nested counterfactuals\n\nFor example, if \\(A\\) is binary, you can think of the following counterfactual \\[\\begin{align}\n  A          &= 1 \\nonumber \\\\\n  Z_1        &= f_Z(W, 1, U_Z) \\nonumber \\\\\n  M          &= M_0 \\nonumber \\\\\n  Y_{1, M_0} &= f_Y(W, 1, Z_1, M_0, U_Y)\n\\end{align}\\]\n\n\n\\(Y_{1, M_0}\\) is interpreted as the outcome for an individual in a hypothetical world where treatment was given but the mediator was held at the value it would have taken under no treatment.\nCausal mediation effects are often defined in terms of the distribution of these nested counterfactuals.\nThat is, causal effects give you information about what would have happened in some hypothetical world where the mediator and treatment mechanisms changed.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal mediation analysis intro</span>"
    ]
  },
  {
    "objectID": "chapters/effects_defn.html",
    "href": "chapters/effects_defn.html",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "",
    "text": "2.1 Controlled direct effects\n\\[\\psi_{\\text{CDE}} = \\E(Y_{1,m} - Y_{0,m})\\]",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "chapters/effects_defn.html#controlled-direct-effects",
    "href": "chapters/effects_defn.html#controlled-direct-effects",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "",
    "text": "Set the mediator to a reference value \\(M=m\\) uniformly for everyone in the population\nCompare \\(A=1\\) vs \\(A=0\\) with \\(M=m\\) fixed\n\n\n2.1.1 Identification assumptions:\n\nConfounder assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\n\nPositivity assumptions:\n\n\\(\\P(M = m \\mid A=a, W) &gt; 0 \\text{  } a.e.\\)\n\\(\\P(A=a \\mid W) &gt; 0 \\text{  } a.e.\\)\n\n\n\nUnder the above identification assumptions, the controlled direct effect can be identified: \\[\n  \\E(Y_{1,m} - Y_{0,m}) = \\E\\{ \\color{ForestGreen}{\\E(Y \\mid A=1, M=m, W) -\n    \\E(Y \\mid A=0, M=m, W)} \\}\n\\]\n\n\nFor intuition about this formula in R, let’s continue with a toy example:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nFirst we fit a correct model for the outcome\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nAssume we would like the CDE at \\(m=0\\)\n\nThen we generate predictions \\[\n  \\color{ForestGreen}{\\E(Y \\mid A=1, M=m, W)} \\text{ and }\n    \\color{ForestGreen}{\\E(Y \\mid A=0, M=m, W)} \\ :\n\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThen we compute the difference between the predicted values \\(\\color{ForestGreen}{\\E(Y \\mid A=1, M=m, W) - \\E(Y \\mid A=0, M=m, W)}\\), and average across values of \\(W\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.1.2 Is this the estimand I want?\n\nMakes the most sense if can intervene directly on \\(M\\)\n\nAnd can think of a policy that would set everyone to a constant level \\(m\n\\in \\mathcal{M}\\).\nJudea Pearl calls this prescriptive.\nCan you think of an example? (Air pollution, rescue inhaler dosage, hospital visits…)\nDoes not provide a decomposition of the average treatment effect into direct and indirect effects.\n\n\n\nWhat if our research question doesn’t involve intervening directly on the mediator?\nWhat if we want to decompose the average treatment effect into its direct and indirect counterparts?",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "chapters/effects_defn.html#natural-direct-and-indirect-effects",
    "href": "chapters/effects_defn.html#natural-direct-and-indirect-effects",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "\n2.2 Natural direct and indirect effects",
    "text": "2.2 Natural direct and indirect effects\nStill using the same DAG as above,\n\nRecall the definition of the nested counterfactual: \\[\\begin{equation*}\n  Y_{1, M_0} = f_Y(W, 1, M_0, U_Y)\n\\end{equation*}\\]\n\nInterpreted as the outcome for an individual in a hypothetical world where treatment was given but the mediator was held at the value it would have taken under no treatment\n\n\nRecall that, because of the definition of counterfactuals \\[\\begin{equation*}\n  Y_{1, M_1} = Y_1\n\\end{equation*}\\]\n\nThen we can decompose the average treatment effect \\(\\E(Y_1-Y_0)\\) as follows\n\\[\\begin{equation*}\n\\E[Y_{1,M_1} - Y_{0,M_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{M_1}}\n  - Y_{\\color{red}{1},\\color{blue}{M_0}}]}_{\\text{natural indirect effect}} +\n  \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{M_0}} -\n  Y_{\\color{blue}{0},\\color{red}{M_0}}]}_{\\text{natural direct effect}}\n\\end{equation*}\\]\n\nNatural direct effect (NDE): Varying treatment while keeping the mediator fixed at the value it would have taken under no treatment\nNatural indirect effect (NIE): Varying the mediator from the value it would have taken under treatment to the value it would have taken under control, while keeping treatment fixed\n\n\n2.2.1 Identification assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\\(A \\indep M_a \\mid W\\)\n\\(M_0 \\indep Y_{1,m} \\mid W\\)\nand positivity assumptions\n\n2.2.2 Cross-world independence assumption\nWhat does \\(M_0 \\indep Y_{1,m} \\mid W\\) mean?\n\nConditional on \\(W\\), knowledge of the mediator value in the absence of treatment, \\(M_0\\), provides no information about the outcome under treatment, \\(Y_{1,m}\\).\nCan you think of a data-generating mechanism that would violate this assumption?\nExample: in a randomized study, whenever we believe that treatment assignment works through adherence (i.e., almost always), we are violating this assumption (more on this later).\nCross-world assumptions are problematic for other reasons, including:\n\nYou can never design a randomized study where the assumption holds by design.\n\n\n\nIf the cross-world assumption holds, can write the NDE as a weighted average of controlled direct effects at each level of \\(M=m\\).\n\\[\n  \\E \\sum_m \\{\\E(Y_{1,m} \\mid W) - \\E(Y_{0,m} \\mid W)\\} \\P(M_{0}=m \\mid W)\n\\]\n\nIf CDE(\\(m\\)) is constant across \\(m\\), then CDE = NDE.\n\n2.2.3 Identification formula:\n\nUnder the above identification assumptions, the natural direct effect can be identified: \\[\\begin{equation*}\n  \\E(Y_{1,M_0} - Y_{0,M_0}) =\n  \\E[\\color{red}{\\E\\{}\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) -\n  \\E(Y \\mid A=0, M, W)}\\color{red}{\\mid A=0,W\\}}]\n\\end{equation*}\\]\nThe natural indirect effect can be identified similarly.\n\nLet’s dissect this formula in R:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nFirst we fit a correct model for the outcome\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThen we generate predictions \\(\\color{ForestGreen}{\\E(Y \\mid A=1, M, W)}\n\\text{ and }\\color{ForestGreen}{\\E(Y \\mid A=0, M, W)}\\) with \\(A\\) fixed but letting \\(M\\) and \\(W\\) take their observed values\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nThen we compute the difference between the predicted values \\(\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) - \\E(Y \\mid A=0, M, W)},\\)\n\nand use this difference as a pseudo-outcome in a regression on \\(A\\) and \\(W\\): \\(\\color{red}{\\E\\{}\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) - \\E(Y \\mid\nA=0, M, W)}\\color{red}{\\mid A=0,W\\}}\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we predict the value of this pseudo-outcome under \\(A=0\\), and average the result\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.2.4 Is this the estimand I want?\n\nMakes sense to intervene on \\(A\\) but not directly on \\(M\\).\nWant to understand a natural mechanism underlying an association / total effect. J. Pearl calls this descriptive.\nNDE + NIE = total effect (ATE).\nOkay with the assumptions.\n\nWhat if our data structure involves a post-treatment confounder of the mediator-outcome relationship (e.g., adherence)?\n\nCode\\dimendef\\prevdepth=0\n\\pgfdeclarelayer{background}\n\\pgfsetlayers{background,main}\n\\usetikzlibrary{arrows,positioning}\n\\tikzset{\n&gt;=stealth',\npunkt/.style={\nrectangle,\nrounded corners,\ndraw=black, very thick,\ntext width=6.5em,\nminimum height=2em,\ntext centered},\npil/.style={\n-&gt;,\nthick,\nshorten &lt;=2pt,\nshorten &gt;=2pt,}\n}\n\\newcommand{\\Vertex}[2]\n{\\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\VertexR}[2]\n{\\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\ArrowR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend right=30] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\ArrowL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend right=-45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\Arrow}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) -- +(#2);\n\\end{pgfonlayer}\n}\n\\begin{tikzpicture}\n  \\Vertex{0, -1}{Z}\n  \\Vertex{-4, 0}{W}\n  \\Vertex{0, 0}{M}\n  \\Vertex{-2, 0}{A}\n  \\Vertex{2, 0}{Y}\n  \\ArrowR{W}{Z}{black}\n  \\Arrow{Z}{M}{black}\n  \\Arrow{W}{A}{black}\n  \\Arrow{A}{M}{black}\n  \\Arrow{M}{Y}{black}\n  \\Arrow{A}{Z}{black}\n  \\Arrow{Z}{Y}{black}\n  \\ArrowL{W}{Y}{black}\n  \\ArrowL{A}{Y}{black}\n  \\ArrowL{W}{M}{black}\n\\end{tikzpicture}\n\n\n\nDirected acyclic graph under intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\n\n\n2.2.5 Unidentifiability of the NDE and NIE in this setting\n\nIn this example, natural direct and indirect effects are not generally point identified from observed data \\(O=(W,A,Z,M,Y)\\).\nThe reason for this is that the cross-world counterfactual assumption \\[\n  Y_{1,m} \\indep M_0 \\mid W\n\\] does not hold in the above directed acyclic graph.\n\nTo give intuition, we focus on the counterfactual outcome \\(Y_{A=1, M_{A=0}}\\).\n\nThis counterfactual outcome involves two counterfactual worlds simultaneously: one in which \\(A=1\\) for the first portion of the counterfactual outcome, and one in which \\(A=0\\) for the nested portion of the counterfactual outcome.\nSetting \\(A=1\\) induces a counterfactual treatment-induced confounder, denoted \\(Z_{A=1}\\). Setting \\(A=0\\) induces another counterfactual treatment-induced confounder, denoted \\(Z_{A=0}\\).\nThe two treatment-induced counterfactual confounders, \\(Z_{A=1}\\) and \\(Z_{A=0}\\) share unmeasured common causes, \\(U_Z\\), which creates a spurious association.\nBecause \\(Z_{A=1}\\) is causally related to \\(Y_{A=1, M=m}\\), and \\(Z_{A=0}\\) is also casually related to \\(M_{A=0}\\), the path through \\(U_Z\\) means that the backdoor criterion is not met for identification of \\(Y_{A=1, M_{A=0}}\\), i.e., \\(M_{0} \\notindep Y_{A=1, m} \\mid W\\), where \\(W\\) denotes baseline covariates.\n\n\n\n\nCode\\dimendef\\prevdepth=0\n\\pgfdeclarelayer{background}\n\\pgfsetlayers{background,main}\n\\usetikzlibrary{arrows,positioning}\n\\tikzset{\n&gt;=stealth',\npunkt/.style={\nrectangle,\nrounded corners,\ndraw=black, very thick,\ntext width=6.5em,\nminimum height=2em,\ntext centered},\npil/.style={\n-&gt;,\nthick,\nshorten &lt;=2pt,\nshorten &gt;=2pt,}\n}\n\\newcommand{\\Vertex}[2]\n{\\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\VertexR}[2]\n{\\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\ArrowR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend right=30] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\ArrowL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend right=-45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\Arrow}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) -- +(#2);\n\\end{pgfonlayer}\n}\n\n\\begin{tikzpicture}\n  \\Vertex{0, 1}{Z_0}\n  \\Vertex{0, -1}{Z_1}\n  \\Vertex{-2, 0}{U_Z}\n  \\Vertex{2, 1}{M_0}\n  \\Vertex{4, -1}{Y_{1, m}}\n  \\Arrow{Z_0}{M_0}{black}\n  \\Arrow{Z_1}{Y_{1, m}}{black}\n  \\Arrow{U_Z}{Z_0}{black}\n  \\Arrow{U_Z}{Z_1}{black}\n\\end{tikzpicture}\n\n\n\nParallel worlds model of the scenario considered\n\n\n\n\n\nHowever:\n\nWe can actually actually identify the NIE/NDE if we are willing to invoke monotonicity between a treatment and one or more binary treatment-induced confounders (Tchetgen Tchetgen and VanderWeele 2014).\nAssuming monotonicity is also sometimes referred to as assuming “no defiers” – in other words, assuming that there are no individuals who would do the opposite of the encouragement.\nMonotonicity may seem like a restrictive assumption, but may be reasonable in some common scenarios (e.g., in trials where the intervention is randomized treatment assignment and the treatment-induced confounder is whether or not treatment was actually taken – in this setting, we may feel comfortable assuming that there are no “defiers”, frequently assumed when using IVs to identify causal effects)\n\n\nTchetgen Tchetgen, Eric J, and Tyler J VanderWeele. 2014. “On Identification of Natural Direct Effects When a Confounder of the Mediator Is Directly Affected by Exposure.” Epidemiology 25 (2): 282.\nNote: CDEs are still identified in this setting. They can be identified and estimated similarly to a longitudinal data structure with a two-time-point intervention.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "chapters/effects_defn.html#randomized-interventional-indirect-effects",
    "href": "chapters/effects_defn.html#randomized-interventional-indirect-effects",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "\n2.3 Randomized interventional (in)direct effects",
    "text": "2.3 Randomized interventional (in)direct effects\n\nLet \\(G_a\\) denote a random draw from the distribution of \\(M_a \\mid W\\)\n\nDefine the counterfactual \\(Y_{1,G_0}\\) as the counterfactual variable in a hypothetical world where \\(A\\) is set \\(A=1\\) and \\(M\\) is set to \\(M=G_0\\) with probability one.\n\n\n\nDefine \\(Y_{0,G_0}\\) and \\(Y_{1,G_1}\\) similarly\nThen we can define: \\[\n  \\E[Y_{1,G_1} - Y_{0,G_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\n    \\color{blue}{G_1}} - Y_{\\color{red}{1},\n    \\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n    Y_{\\color{blue}{0},\n    \\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\]\nNote that \\(\\E[Y_{1,G_1} - Y_{0,G_0}]\\) is still an overall effect of treatment, even if it is different from the ATE \\(\\E[Y_{1} - Y_{0}]\\)\nWe gain in the ability to solve a problem, but lose in terms of interpretation of the causal effect (cannot decompose the ATE)\n\n\n2.3.1 An alternative definition of the effects:\n\nAbove we defined \\(G_a\\) as a random draw from the distribution of \\(M_a \\mid W\\)\n\nWhat if instead we define \\(G_a\\) as a random draw from the distribution of \\(M_a\n\\mid (Z_a,W)\\)\n\nIt turns out the indirect effect defined in this way only measures the path \\(A\\rightarrow M \\rightarrow Y\\), and not the path \\(A\\rightarrow Z\\rightarrow M\n\\rightarrow Y\\)\n\nThere may be important reasons to choose one over another (e.g., survival analyses where we want the distribution conditional on \\(Z\\), instrumental variable designs where it doesn’t make sense to condition on \\(Z\\))\n\n\n2.3.2 Identification assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A, Z\\)\n\\(A \\indep M_a \\mid W\\)\nand positivity assumptions.\n\nUnder these assumptions, the randomized interventional direct and indirect effect is identified: \\[\\begin{align*}\n  \\E &(Y_{a, G_{a'}}) = \\\\\n     & \\E\\left[\\color{Purple}{\\E\\left\\{\\color{red}{\\sum_z}\n      \\color{ForestGreen}{\\E(Y \\mid A=a, Z=z, M, W)}\n      \\color{red}{\\P(Z=z \\mid A=a, W)}\\mid A=a', W\\right\\}} \\right]\n\\end{align*}\\]\n\n\nLet’s dissect this formula in R:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nLet us compute \\(\\E(Y_{1, G_0})\\) (so that \\(a = 1\\), and \\(a'=0\\)).\n\nFirst, fit a regression model for the outcome, and compute \\(\\color{ForestGreen}{\\E(Y \\mid A=a, Z=z, M, W)}\\) for all values of \\(z\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we fit the true model for \\(Z \\mid A, W\\) and get the conditional probability that \\(Z=1\\) fixing \\(A=1\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we compute the following pseudo-outcome: \\(\\color{red}{\\sum_z}\\color{ForestGreen}{\\E(Y \\mid A=a, Z=z, M, W)}\n\\color{red}{\\P(Z=z \\mid A=a, w)}\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we regress this pseudo-outcome on \\(A,W\\), and compute the predictions setting \\(A=0\\), that is, []\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nAnd finally, just average those predictions!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis was for \\((a,a')=(1,0)\\). Can do the same with \\((a,a')=(1,1)\\), and \\((a,a')=(0,0)\\) to obtain an effect decomposition\n\\[\\begin{equation*}\n  \\E[Y_{1,G_1} - Y_{0,G_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\n    \\color{blue}{G_1}} -\n    Y_{\\color{red}{1},\n    \\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n    Y_{\\color{blue}{0},\n    \\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\end{equation*}\\]\n\n\n2.3.3 Is this the estimand I want?\n\nMakes sense to intervene on \\(A\\) but not directly on \\(M\\).\nGoal is to understand a descriptive type of mediation.\nOkay with the assumptions!\n\n2.3.4 But, there is an important limitation of randomized interventional effects\nMiles (2022) recently uncovered an important limitation of these effects, which can be described as follows. The sharp mediational hull hypothesis can be defined as\n\nMiles, Caleb H. 2022. “On the Causal Interpretation of Randomized Interventional Indirect Effects.” arXiv Preprint arXiv:2203.00245. https://arxiv.org/abs/2203.00245.\n\\[\n  H_0:Y(a, M(a')) = Y(a, M(a^\\star));\\text{ for all }a, a', a^\\star \\ .\n\\]\nThe problem is that randomized interventional effects are not guaranteed to be null when the sharp mediational hypothesis is true.\nThis could present a problem in practice if some subgroup of the population has a relationship between \\(A\\) and \\(M\\), but not between \\(M\\) and \\(Y\\). Then, another distinct subgroup of the population has a relationship between \\(M\\) and \\(Y\\) but not between \\(A\\) and \\(M\\). In such a scenario, the randomized interventional indirect effect would be nonzero, but there would be no one person in the population whose effect of \\(A\\) on \\(Y\\) would be mediated by \\(M\\).\n\nMore details in the original paper.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "chapters/effects_defn.html#path-specific-effects-using-recanting-twins",
    "href": "chapters/effects_defn.html#path-specific-effects-using-recanting-twins",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "\n2.4 Path-specific effects using recanting twins\n",
    "text": "2.4 Path-specific effects using recanting twins\n\nThe DAG we are working under contains four paths of interest:\n\\[\\begin{align*}\nP_1&: A\\rightarrow Y;\\\\\nP_2&: A \\rightarrow Z \\rightarrow Y;\\\\\nP_3&: A \\rightarrow Z \\rightarrow M \\rightarrow Y\\\\\nP_4&: A \\rightarrow M \\rightarrow Y,\n\\end{align*}\\]\nNatural path-specific effects could be defined using the following nested counterfactuals: \\[\\begin{align*}\n  Y_{S_0}&=Y(1, Z(1), M(1, Z(1))),\\\\\n  Y_{S_1}&=Y(0, Z(1), M(1, Z(1))),\\\\\n  Y_{S_2}&=Y(0, Z(0), M(1, Z(1))),\\\\\n  Y_{S_3}&=Y(0, Z(0), M(1, Z(0))),\\\\\n  Y_{S_4}&=Y(0, Z(0), M(0, Z(0))),\n\\end{align*}\\]\nAs before, the problem is that the distribution of \\(Y_{S_2}\\) is not identifiable due to the so-called recanting witness \\(Z\\). This means that one can contrast \\(Y_{S_1}\\) with \\(Y_{S_3}\\) but not with \\(Y_{S_2}\\). Thus, the effects operating through \\(P_2\\) and \\(P_3\\) cannot be disentangled.\n\\(Z\\) is called a recanting witness because “it tells one story” Z(1) for purposes of one path, and another story $Z(0) for purposes of the other.\nBut what if we replaced recanting witnesses by randomized versions of them that carry some of the same information? Specifically, if \\(T(a)\\) is a random draw from the distribution of \\(Z(a)\\) conditional on \\(W\\), we can:\n\nMeasure \\(P_2\\) by contrasting \\[Y(0, Z(1), M(1, {\\color{ForestGreen}{T(1)}})) \\text{ vs } Y(0, Z(0), M(1, \\color{ForestGreen}{T(1)}))\\]\nMeasure \\(P_3\\) by contyrasting \\[Y(0, {\\color{ForestGreen}{T(0)}}, M(1, Z(1))) \\text{ vs } Y(0, {\\color{ForestGreen}{T(0)}}, M(1, Z(0)))\\]\nMeasure the other paths through their identified natural effects\n\nThis is what we proposed in a recent paper (Vo et al. (2024)).\n\nVo, Tat-Thang, Nicholas Williams, Richard Liu, Kara E Rudolph, and Ivan Dıaz. 2024. “Recanting Twins: Addressing Intermediate Confounding in Mediation Analysis.” arXiv Preprint arXiv:2401.04450.\nThe variables \\(T(a)\\) are the recanting twins of \\(Z(1-a)\\). Identification requires some of the standard assumptions, namely:\n\n\n\\(U_A\\indep (U_Y, U_M, U_Z)\\mid W\\),\n\n\\(U_Z\\indep (U_Y, U_M)\\mid (A,W)\\), and\n\n\\(U_M\\indep U_Y\\mid (Z,A,W)\\).\n\nUnder these assumptions, we can identify a decomposition of the ATE as follows:\n\\[\\text{ATE} = \\psi_{P_1} + \\psi_{P_2} + \\psi_{P_3} + \\psi_{P_4} +\n  \\psi_{\\text{IC}},\\]\nwhere\n\n\n\\(\\psi_{P_i}\\) measures the effect through path \\(P_i\\)\n\n\n\\(\\psi_{\\text{IC}}\\) is a remainder that is equal to zero if there is no intermediate confounding, in which case \\(\\psi_{P_i}\\) is equal to the (identified) natural path-specific effect.\n\nMore details on the definition, interpretation, and identification of these effects in the paper!",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "chapters/how_to_choose.html",
    "href": "chapters/how_to_choose.html",
    "title": "3  How to choose an estimand: Real-world example",
    "section": "",
    "text": "3.1 1. Extent to which the risk of OUD conferred by chronic pain operates through pain management treatments\nThis application was explored in detail by Rudolph et al. (2025)",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>How to choose an estimand: Real-world example</span>"
    ]
  },
  {
    "objectID": "chapters/how_to_choose.html#extent-to-which-the-risk-of-oud-conferred-by-chronic-pain-operates-through-pain-management-treatments",
    "href": "chapters/how_to_choose.html#extent-to-which-the-risk-of-oud-conferred-by-chronic-pain-operates-through-pain-management-treatments",
    "title": "3  How to choose an estimand: Real-world example",
    "section": "",
    "text": "3.1.1 Getting specific about the question\nTo what extent does the total effect of chronic pain on risk of OUD operate through prescription medications for pain management and physical therapy, treated as a bundle?\n\nWhat estimand do we want?\n\n\nCan we set \\(M=m\\) (i.e., same value) for everyone?\nAre we interested in estimating indirect effects?\n\n\\(\\rightarrow\\) So, not controlled direct effect.\n\nDo we have an intermediate confounder?\n\nNot really, because we: 1) consider all initial treatments following chronic pain diagnosis and 2) stratify by whether or not the patient has an anxiety or depressive disorder.\n\n\n\n\\(\\rightarrow\\) So, could estimate natural (in)direct effects\n\nEstimands:\n\nDirect effect: \\(\\E(Y_{1,M_0} - Y_{0,M_0})\\)\n\nIndirect effect: \\(\\E(Y_{1,M_1} - Y_{1,M_0})\\)",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>How to choose an estimand: Real-world example</span>"
    ]
  },
  {
    "objectID": "chapters/how_to_choose.html#extent-to-which-the-risk-of-oud-conferred-by-chronic-pain-operates-through-individual-pain-management-treatments",
    "href": "chapters/how_to_choose.html#extent-to-which-the-risk-of-oud-conferred-by-chronic-pain-operates-through-individual-pain-management-treatments",
    "title": "3  How to choose an estimand: Real-world example",
    "section": "\n3.2 2. Extent to which the risk of OUD conferred by chronic pain operates through individual pain management treatments",
    "text": "3.2 2. Extent to which the risk of OUD conferred by chronic pain operates through individual pain management treatments\n\nThis application was explored in detail by Rudolph et al. (2025)\n\nRudolph, Kara E, Shodai Inose, Nicholas T Williams, Katherine L Hoffman, Sarah E Forrest, Rachael K Ross, Floriana Milazzo, et al. 2025. “Mediation of Chronic Pain and Disability on Opioid Use Disorder Risk by Pain Management Practices Among Adult Medicaid Patients, 2016-2019.” American Journal of Epidemiology, kwaf093.\n\n3.2.1 Getting specific about the question\nTo what extent does the overall effect of chronic pain on risk of OUD operate through individual pain management treatments, controlling for other co-occurring or prior pain treatments?\n\nWhat estimand do we want?\n\n\nCan we set \\(M=m\\) (i.e., same value) for everyone?\nAre we interested in estimating indirect effects?\n\n\\(\\rightarrow\\) So, not controlled direct effect.\n\nDo we have an intermediate confounder?\n\nYes, likely multiple, important ones, because we would like to control for prior or co-occurring pain treatments.\nSo likely do not have a single, binary intermediate confounder.\nIf we do have a binary intermediate confounder, would we assume monotonicity between the treatment and intermediate confounder?\n\nNo\n\n\n\n\n\n\\(\\rightarrow\\) Randomized interventional direct and indirect effects.\n\nDo we want to estimate the path through treatment initiation (\\(Z\\))?\n\nYes, so, not the conditional versions of these effects.\nHere \\(G_a\\) is a draw from the distribution of \\(M_a\\mid W\\).\n\n\nEstimands:\n\nDirect effect: \\(\\E(Y_{1,G_0} - Y_{0,G_0})\\)\n\nIndirect effect: \\(\\E(Y_{1,G_1} - Y_{1,G_0})\\)\n\n\n\nNeed to incorporate multiple and continuous intermediate confounders\n\n\n\nWhat if the positivity assumption \\(\\P(A=a\\mid W)&gt;0\\) violated?\n\\(\\rightarrow\\) Can’t identify or estimate any of the above effects\n\nBut we can estimate the effect of some stochastic interventions, e.g., IPSIs\nTrade-off between feasibility and interpretation\n\n\n\nWhat if the exposure variable is continuous?\n\\(\\rightarrow\\) All the above effects are defined for binary exposures\n\nBut we can estimate the effect of some stochastic interventions and general interventions on continuous exposures, like shift interventions.\n\n\nWhat if the exposure is actually time-varying? What if the mediators and/or intermediate confounders are actually time-varying?",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>How to choose an estimand: Real-world example</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_prelims.html",
    "href": "chapters/estimation_prelims.html",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "",
    "text": "4.1 Option 1: G-computation estimator\nRecall our motivation for doing mediation analysis. We would like to decompose the total effect of a treatment \\(A\\) on an outcome \\(Y\\) into effects that operate through a mediator \\(M\\) vs effects that operate independently of \\(M\\).\nRecall that we define the average treatment effect as \\(E(Y_1-Y_0)\\), and decompose it as follows\n\\[\n\\E[Y_{1,M_1} - Y_{0,M_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{M_1}}\n    - Y_{\\color{red}{1},\\color{blue}{M_0}}]}_{\\text{natural indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{M_0}} -\n    Y_{\\color{blue}{0},\\color{red}{M_0}}]}_{\\text{natural direct effect}}\n\\]\nTo introduce some of the ideas that we will use for estimation of the NDE, let us first briefly discuss estimation of \\(\\E(Y_1)\\) (estimation of \\(\\E(Y_0)\\) can be performed analogously).\nFirst, notice that under the assumption of no unmeasured confounders (\\(Y_1\\indep A\\mid W\\)), we have\n\\[\n  \\E(Y_1) = \\E[ \\E(Y \\mid A=1, W) ]\n\\]\nThe first estimator of \\(\\E[ \\E(Y \\mid A=1, W) ]\\) can be obtained in a three-step procedure:\nIn formulas, this estimator can be written as \\[\\frac{1}{n} \\sum_{i=1}^n\n\\hat{\\E}(Y \\mid A_i=1, W_i)\\]",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_prelims.html#option-1-g-computation-estimator",
    "href": "chapters/estimation_prelims.html#option-1-g-computation-estimator",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "",
    "text": "Fit a regression for \\(Y\\) on \\(A\\) and \\(W\\)\n\nUse the above regression to predict the outcome mean if everyone’s \\(A\\) is set to \\(A=1\\)\n\nAverage these predictions\n\n\n\nNote that this is just a plug-in estimator for the above formula (called the g-formula): \\(\\E[\\E(Y \\mid A=1, W)]\\)\n\nThis estimator requires that the regression model for \\(\\hat{\\E}(Y \\mid A_i=1,\nW_i)\\) is correctly specified.\nDownside: If we use machine learning for this model, we do not have general theory for computing standard errors and confidence intervals",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_prelims.html#option-2-inverse-probability-weighted-estimator",
    "href": "chapters/estimation_prelims.html#option-2-inverse-probability-weighted-estimator",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "\n4.2 Option 2: Inverse probability weighted estimator",
    "text": "4.2 Option 2: Inverse probability weighted estimator\nAn alternative method of estimation can be constructed after noticing that \\[\\E[ \\E(Y \\mid A=1, W) ] = \\E\\left[ \\frac{A}{\\P(A=1\\mid W)} Y \\right],\\] using the following procedure:\n\nFit a regression for \\(A\\) and \\(W\\)\n\nUse the above regression to predict the probability of treatment \\(A=1\\)\n\nCompute the inverse probability weights \\(A_i / \\hat{\\P}(A_i =1 \\mid W_i)\\).\nThis weight will be zero for untreated units, and the inverse of the probability of treatment for treated units.\nCompute the weighted average of the outcome: \\[\\frac{1}{n} \\sum_{i=1}^n\n\\frac{A_i}{\\hat{\\P}(A_i=1 \\mid W_i)} Y_i\\]\n\nThis estimator requires that the regression model for \\(\\hat{\\P}(A=1 \\mid\nW_i)\\) is correctly specified.\nDownside: If we use machine learning for this model, we do not have general theory for computing standard errors and confidence intervals",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_prelims.html#option-3-augmented-inverse-probability-weighted-estimator",
    "href": "chapters/estimation_prelims.html#option-3-augmented-inverse-probability-weighted-estimator",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "\n4.3 Option 3: Augmented inverse probability weighted estimator",
    "text": "4.3 Option 3: Augmented inverse probability weighted estimator\nFortunately, we can combine these two estimators to get an estimator with improved properties.\nThe improved estimator can be seen both as a corrected (or augmented) IPW estimator: \\[\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\frac{A_i}{\\hat{\\P}(A_i=1 \\mid W_i)}\nY_i}_{\\text{IPW estimator}} -\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\frac{\\hat{\\E}(Y \\mid A_i=1, W_i)}\n  {\\hat{\\P}(A_i=1 \\mid W_i)}[A_i - \\hat{\\P}(A_i=1 \\mid\n  W_i)]}_{\\text{Correction term}}\n\\]\nor\n\\[\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\hat{\\E}(Y \\mid A_i=1,\n  W_i)}_{\\text{G-comp estimator}} +\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\frac{A_i}{\\hat{\\P}(A_i=1\\mid W_i)}\n  [Y_i - \\hat{\\E}(Y \\mid A_i=1, W_i)]}_{\\text{Correction term}}\n\\]\nThis estimator has some desirable properties:\n\nIt is robust to misspecification of at most one of the models (outcome or treatment) (Q: can you see why?)\nIt is distributed as a normal random variable as sample size grows. This allows us to easily compute confidence intervals and do hypothesis tests\nIt allows us to use machine learning to estimate the treatment and outcome regressions to alleviate model misspecification bias\n\nNext, we will work towards constructing estimators with these same properties for the mediation parameters that we have introduced.",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_natural_interv.html",
    "href": "chapters/estimation_natural_interv.html",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "",
    "text": "5.1 Recap: Definition and identification of the NDE\nRecall:\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment\nThis SCM is represented in the above DAG and the following causal models: \\[\\begin{align*}\n  W & = f_W(U_W) \\\\\n  A & = f_A(W, U_A) \\\\\n  M & = f_M(W, A, U_M) \\\\\n  Y & = f_Y(W, A, M, U_Y),\n\\end{align*}\\] where \\((U_W, U_A,U_M, U_Y)\\) are exogenous random errors.\nRecall that we need to assume the following to identify the above causal effects from our observed data:\nThen, the NDE is identified as \\[\n    \\psi(\\P) = \\E[\\E\\{\\E(Y \\mid A=1, M, W) - \\E(Y \\mid A=0, M, W) \\mid A=0,W\\}]\n  \\]",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_natural_interv.html#recap-definition-and-identification-of-the-nde",
    "href": "chapters/estimation_natural_interv.html#recap-definition-and-identification-of-the-nde",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "",
    "text": "Assuming a binary \\(A\\), we define the natural direct effect as: \\(\\text{NDE} = \\E(Y_{1,M_{0}} - Y_{0,M_{0}})\\).\nand the natural indirect effect as: \\(\\text{NIE} = \\E(Y_{1,M_{1}} - Y_{1,M_{0}})\\).\nThe observed data is \\(O = (W, A, M, Y)\\)\n\n\n\n\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\\(A \\indep M_a \\mid W\\)\n\\(M_0 \\indep Y_{1,m} \\mid W\\)\nand positivity assumptions",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_natural_interv.html#from-causal-to-statistical-quantities",
    "href": "chapters/estimation_natural_interv.html#from-causal-to-statistical-quantities",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.2 From causal to statistical quantities",
    "text": "5.2 From causal to statistical quantities\n\nWe have arrived at identification formulas that express quantities that we care about in terms of observable quantities\nThat is, these formulas express what would have happened in hypothetical worlds in terms of quantities observable in this world.\nThis required causal assumptions\n\nMany of these assumptions are empirically unverifiable\nWe saw an example where we could relax the cross-world assumption, at the cost of changing the parameter interpretation (when we introduced randomized interventional direct and indirect effects).\nWe also include an extra section at the end about stochastic randomized interventional direct and indirect effects, which allow us to relax the positivity assumption, also at the cost of changing the parameter interpretation.\n\n\nWe are now ready to tackle the estimation problem, i.e., how do we best learn the value of quantities that are observable?\nThe resulting estimation problem can be tackled using statistical assumptions of various degrees of strength\n\nMost of these assumptions are verifiable (e.g., a linear model)\nThus, most are unnecessary (except for convenience)\nWe have worked hard to try to satisfy the required causal assumptions\nThis is not the time to introduce unnecessary statistical assumptions\nThe estimation approach we will minimizes reliance on these statistical assumptions.",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_natural_interv.html#computing-identification-formulas-if-you-know-the-true-distribution",
    "href": "chapters/estimation_natural_interv.html#computing-identification-formulas-if-you-know-the-true-distribution",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.3 Computing identification formulas if you know the true distribution",
    "text": "5.3 Computing identification formulas if you know the true distribution\n\nThe mediation parameters that we consider can be seen as a function of the joint probability distribution of observed data \\(O=(W,A,Z,M,Y)\\)\n\nFor example, under identifiability assumptions the natural direct effect is equal to \\[\n  \\psi(\\P) = \\E[\\color{Goldenrod}{\\E\\{\\color{ForestGreen}\n    {\\E(Y \\mid A=1, M, W) - \\E(Y \\mid A=0, M, W)} \\mid A=0, W \\}}]\n\\]\n\nThe notation \\(\\psi(\\P)\\) means that the parameter is a function of \\(\\P\\) – in other words, that it is a function of this joint probability distribution\nThis means that we can compute it for any distribution \\(\\P\\)\n\nFor example, if we know the true \\(\\P(W,A,M,Y)\\), we can comnpute the true value of the parameter by:\n\nComputing the conditional expectation \\(\\E(Y\\mid A=1,M=m,W=w)\\) for all values \\((m,w)\\)\n\nComputing the conditional expectation \\(\\E(Y\\mid A=0,M=m,W=w)\\) for all values \\((m,w)\\)\n\nComputing the probability \\(\\P(M=m\\mid A=0,W=w)\\) for all values \\((m,w)\\)\n\nCompute \\[\\begin{align*}\n  \\color{Goldenrod}{\\E\\{}&\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) -\n    \\E(Y \\mid A=0, M, W)}\\color{Goldenrod}{\\mid A=0,W\\}} =\\\\\n  &\\color{Goldenrod}{\\sum_m\\color{ForestGreen}{\\{\\E(Y \\mid A=1, m, w) -\n    \\E(Y \\mid A=0, m, w)\\}} \\P(M=m\\mid A=0, W=w)}\n\\end{align*}\\]\n\nComputing the probability \\(\\P(W=w)\\) for all values \\(w\\)\n\nComputing the mean over all values \\(w\\)",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_natural_interv.html#plug-in-and-re-weighting-estimators",
    "href": "chapters/estimation_natural_interv.html#plug-in-and-re-weighting-estimators",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.4 Plug-in and re-weighting estimators",
    "text": "5.4 Plug-in and re-weighting estimators\n\n5.4.1 Plug-in (aka g-computation) estimator\nThe above is how you would compute the true value if you know the true distribution \\(\\P\\)\n\nThis is exactly what we did in our R examples before\nBut we can use the same logic for estimation:\n\nFit a regression to estimate, say \\(\\hat\\E(Y\\mid A=1,M=m,W=w)\\)\n\nFit a regression to estimate, say \\(\\hat\\E(Y\\mid A=0,M=m,W=w)\\)\n\nCompute the pseudo-outcome \\(\\hat\\E(Y\\mid A=1,M=m,W=w) -\n\\hat\\E(Y\\mid A=0,M=m,W=w)\\), then regress it on \\((A, W)\\) to obtain \\(\\hat\\E\\{\\hat\\E(Y\\mid A=1,M=m,W=w) - \\hat\\E(Y\\mid A=0,M=m,W=w) \\mid A, W\\}\\) \n\nEstimate \\(\\P(W=w)\\) with the empirical distribution\nEvaluate \\[\n  \\psi(\\hat\\P) = \\hat{\\E}[\\color{RoyalBlue}{\n    \\hat{\\E}\\{\\color{Goldenrod}{\\hat\\E(Y \\mid A=1, M, W) -\n    \\hat{\\E}(Y \\mid A=0, M, W)}\\mid A=0,W\\}}]\n\\]\n\n\n\nThis is known as the G-computation estimator.\n\n5.4.2 Reweighting (aka IPW) estimators\n\n5.4.2.1 First weighted estimator (like inverse probability weighted)\n\nAn alternative expression of the parameter functional (for the NDE) is given by \\[\n  \\E \\bigg[\\color{RoyalBlue}{\\bigg\\{ \\frac{\\I(A=1)}{\\P(A=1\\mid W)}\n  \\frac{\\P(M\\mid A=0,W)}{\\P(M\\mid A=1,W)} -\n  \\frac{\\I(A=0)}{\\P(A=0\\mid W)}\\bigg\\}} \\times \\color{Goldenrod}{Y}\\bigg]\n\\]\n\nThus, you can also construct a weighted estimator as \\[\n  \\frac{1}{n} \\sum_{i=1}^n \\bigg[\\color{RoyalBlue}{\\bigg\\{\n  \\frac{\\I(A_i=1)}{\\hat{\\P}(A_i=1\\mid W_i)}\n  \\frac{\\hat{\\P}(M_i\\mid A_i=0,W_i)}{\\hat{\\P}(M_i\\mid A_i=1, W_i)} -\n  \\frac{\\I(A_i=0)}{\\hat{\\P}(A_i=0\\mid W_i)}\\bigg\\}} \\times\n  \\color{Goldenrod}{Y_i} \\bigg]\n\\]\n\n\n5.4.2.2 Second weighted estimator\n\nThe parameter functional for the NDE can also be expressed as a combination of regression and weighting: \\[\n  \\E\\bigg[\\color{RoyalBlue}{\\frac{\\I(A=0)}{\\P(A=0\\mid W)}}\n  \\times \\color{Goldenrod}{\\E(Y \\mid A=1, M, W) -\n  \\E(Y \\mid A=0, M, W)}\\bigg]\n\\]\nThus, you can also construct a weighted estimator as \\[\n  \\frac{1}{n} \\sum_{i=1}^n \\bigg[\\color{RoyalBlue}{\n  \\frac{\\I(A_i=0)}{\\hat{\\P}(A_i=0\\mid W_i)}} \\times\n  \\color{Goldenrod}{\\hat{\\E}(Y \\mid A=1, M_i, W_i) -\n  \\hat{\\E}(Y \\mid A=0, M_i, W_i)}\\bigg]\n\\]\n\n5.4.3 Implementation of g-computation and IPW estimators in practice?\n\nThere are two possible ways to do G-computation or weighted estimation:\n\nUsing parametric models for the above regressions\nUsing flexible data-adaptive regression (aka machine learning)\n\n\n\n5.4.4 Pros and cons of g-computation and IPW with parametric modeling\n\nPros:\n\nEasy to understand\nEase of implementation (standard regression software)\nCan use the Delta method or the bootstrap for computation of standard errors\n\n\nCons:\n\nUnless \\(W\\) and \\(M\\) contain very few categorical variables, it is very easy to misspecify the models\nThis can introduce sizable bias in the estimators\nThis modelling assumptions have become less necessary in the presence of data-adaptive regression tools (a.k.a., machine learning)\n\n\n\n5.4.5 Example: Bias of a parametric g-computation estimator of the NDE\n\n\nThe following R chunk provides simulation code to exemplify the bias of a parametric g-computation estimator in a simple situation\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nLet’s perform a simulation where we draw 1000 datasets from the above distribution, and compute a parametric g-computation estimator based on\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe bias also affects the confidence intervals:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n5.4.6 Pros and cons of g-computation or IPW with data-adaptive regression\n\nPros:\n\nEasy to understand.\nAlleviate model-misspecification bias.\n\n\nCons:\n\nMight be harder to implement depending on the regression procedures used.\nNo general approaches for computation of standard errors and confidence intervals.\nFor example, the bootstrap is not guaranteed to work, and it is known to fail in some cases.\n\n\n\n5.4.7 Solution: Robust semi-parametric efficient estimation\n\nIntuitively, it combines the three above estimators to obtain an estimator with improved robustness properties\nIt offers a way to use data-adaptive regression to\n\navoid model misspecification bias,\nendow the estimators with additional robustness (e.g., multiple robustness), while\nallowing the computation of correct standard errors and confidence intervals using Gaussian approximations",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_natural_interv.html#semi-parametric-efficient-estimators-for-the-nde",
    "href": "chapters/estimation_natural_interv.html#semi-parametric-efficient-estimators-for-the-nde",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.5 Semi-parametric efficient estimators (for the NDE)",
    "text": "5.5 Semi-parametric efficient estimators (for the NDE)\n\n5.5.1 Constructing a semi-parametric efficient estimator (aka the one-step)\n\n\nHere we show the detail of how to construct an estimator for the NDE for illustration, but the construction of this estimator is a bit involved and may be complex in daily research practice\nFor practice, we will teach you how to use our package crumbe for automatic implementation of these estimators of the NDE and other parameters\n\nFirst, we need to introduce some notation to describe the EIF for the NDE\n\nLet \\(Q(M, W)\\) denote \\(\\E(Y\\mid A=1, M, W) - \\E(Y\\mid A=0, M, W)\\)\n\nWe can now introduce the semiparametric efficient estimator:\n\n\\[\\begin{align*}\n    \\hat{\\psi} &= \\frac{1}{n} \\sum_{i=1}^n \\color{RoyalBlue}{\\bigg\\{\n      \\frac{\\I(A_i=1)}{\\hat{\\P}(A_i=1 \\mid W_i)}\n      \\frac{\\hat{\\P}(M_i \\mid A_i=0,W)_i}{\\hat{\\P}(M_i \\mid A_i=1,W_i)} -\n      \\frac{\\I(A=0)}{\\hat{\\P}(A_i=0 \\mid W_i)}\\bigg\\}}\n      \\color{Goldenrod}{[Y_i - \\hat{\\E}(Y\\mid A_i,M_i,W_i)]} \\\\\n    &+ \\frac{1}{n} \\sum_{i=1}^n \\color{RoyalBlue}{\\frac{\\I(A=0)}{\\P(A=0 \\mid\n      W)}} \\color{Goldenrod}{\\big\\{ \\hat{Q}(M_i,W_i) -\n      \\hat{\\E}[\\hat{Q}(M_i,W_i) \\mid W_i, A_i = 0] \\big\\}} \\\\\n    &+ \\frac{1}{n} \\sum_{i=1}^n \\color{Goldenrod}{\n      \\hat{\\E}[\\hat{Q}(M_i,W_i) \\mid W_i,A_i=0]}\n\\end{align*}\\]\n\n\nIn this estimator, you can recognize elements from the G-computation estimator and the weighted estimators:\n\nThe third line is the G-computation estimator\nThe second line is a centered version of the second weighted estimator\nThe first line is a centered version of the first weighted estimator\n\n\n\nEstimating \\(\\P(M\\mid A, W)\\) is a very challenging problem when \\(M\\) is high-dimensional. Here we have two options:\n\nOption 1: Since we have the ratio of these conditional densities, we can re-parameterize using Bayes’ rule to get something that is easier to compute: \\[\\begin{equation*}\n\\frac{\\P(M \\mid A=0, W)}{\\P(M \\mid A=1,W)} = \\frac{\\P(A = 0 \\mid M, W)\n         \\P(A=1 \\mid W)}{\\P(A = 1 \\mid M, W) \\P(A=0 \\mid W)} \\ .\n\\end{equation*}\\] Thus we can change the expression of the estimator a bit as follows. First, some more notation that will be useful later:\n\nLet \\(g(a\\mid w)\\) denote \\(\\P(A=a\\mid W=w)\\)\n\nLet \\(e(a\\mid m, w)\\) denote \\(\\P(A=a\\mid M=m, W=w)\\)\n\nLet \\(b(a, m, w)\\) denote \\(\\E(Y\\mid A=a, M=m, W=w)\\)\n\nThe quantity being averaged can be re-expressed as follows \\[\\begin{align*}     \n& \\color{RoyalBlue}{\\bigg\\{ \\frac{\\I(A=1)}{g(0\\mid W)}\n\\frac{e(0\\mid M,W)}{e(1\\mid M,W)} - \\frac{\\I(A=0)}{g(0\\mid W)}\\bigg\\}}\n\\times \\color{Goldenrod}{[Y - b(A,M,W)]} \\\\\n&+ \\color{RoyalBlue}{\\frac{\\I(A=0)}{g(0\\mid W)}}\n\\color{Goldenrod}{\\big\\{Q(M,W) - \\E[Q(M,W) \\mid W, A=0] \\big\\}} \\\\\n&+ \\color{Goldenrod}{\\E[Q(M,W) \\mid W, A=0]}\n\\end{align*}\\]\n\n\n\nOption 2: Use so-called Riesz learning (more on this later)\n\n\n\nIn this section we will use Option 1. The R package crumble that automates all of this uses Option 2.\n\n5.5.2 How to compute the one-step estimator (like Augmented IPW)\nFirst we will generate some data:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nRecall that the semiparametric efficient estimator can be computed in the following steps:\n\n\nFit models for \\(g(a\\mid w)\\), \\(e(a\\mid m, w)\\), and \\(b(a, m, w)\\)\n\nIn this example we will use Generalized Additive Models for tractability\nIn applied settings we recommend using an ensemble of data-adaptive regression algorithms, such as the Super Learner (van der Laan, Polley, and Hubbard 2007)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCompute predictions \\(g(1\\mid w)\\), \\(g(0\\mid w)\\), \\(e(1\\mid m, w)\\), \\(e(0\\mid m, w)\\),\\(b(1, m, w)\\), \\(b(0, m, w)\\), and \\(b(a, m, w)\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCompute \\(Q(M, W)\\), fit a model for \\(\\E[Q(M,W) \\mid W,A]\\), and predict at \\(A=0\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nEstimate the weights\n\\[\\begin{equation*}\n\\color{RoyalBlue}{\\bigg\\{\n  \\frac{\\I(A=1)}{g(0\\mid W)} \\frac{e(0 \\mid M,W)}{e(1 \\mid M,W)} -\n  \\frac{\\I(A=0)}{g(0\\mid W)} \\bigg\\}}\n\\end{equation*}\\] using the above predictions:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCompute the uncentered EIF:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe one step estimator is the mean of the uncentered EIF\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nvan der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” Statistical Applications in Genetics and Molecular Biology 6 (1).\n\n5.5.3 Performance of the one-step estimator in a small simulation study\nFirst, we create a wrapper around the estimator\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLet us first examine the bias\n\nThe true value is:\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nBias simulation\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nAnd now the confidence intervals:\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n5.5.4 On targeted minimum loss-based estimation (TMLE)\n\nThe above estimator is great because it allows us to use data-adaptive regression to avoid bias, while allowing the computation of correct standard errors\nThis estimator has a problem, though:\n\nIt can yield answers outside of the bounds of the parameter space\nE.g., if \\(Y\\) is binary, it could yield direct and indirect effects outside of \\([-1,1]\\)\n\nTo solve this, you can compute a TMLE instead (implemented in the R packages, coming up)\n\n\n\n5.5.5 On cross-fitting\n\nWhen using data-adaptive regression estimators, it is recommended to use cross-fitted estimators\nCross-fitting is similar to cross-validation:\n\nRandomly split the sample into K (e.g., K=10) subsets of equal size\nFor each of the 9/10ths of the sample, fit the regression models\nUse the out-of-sample fit to predict in the remaining 1/10th of the sample\n\n\nCross-fitting further reduces the bias of the estimators\nCross-fitting aids in guaranteeing the correctness of the standard errors and confidence intervals\nCross-fitting is implemented by default in the R packages that you will see next",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_walkthrough.html",
    "href": "chapters/estimation_walkthrough.html",
    "title": "\n6  R packages for estimation of the causal (in)direct effects\n",
    "section": "",
    "text": "6.1 crumble: Flexible and general mediation analysis\nWe’ll now turn to working through a few examples of estimating the natural and interventional direct and indirect effects. We will be using the crumble R package, which provides a unified framework for estimating many of the common mediation estimands, and supports high-dimensional exposures, mediators, and mediator-outcome confounders. However, many software implementations exist in the R ecosystem for performing mediation analyses; notably, crumble was heavily inspired by medoutcon, HDmediation, and lcm.\nAs our running example, we’ll use a simple data set from an observational study of the relationship between BMI and kids’ behavior, freely distributed with the mma R package on CRAN. First, let’s load the packages we’ll be using and set a seed for reproducibility; then, load this data set and take a quick look.\nThe documentation for the data set describes it as a “database obtained from the Louisiana State University Health Sciences Center, New Orleans, by Dr. Richard Scribner. He explored the relationship between BMI and kids’ behavior through a survey at children, teachers and parents in Grenada in 2014. This data set includes 691 observations and 15 variables.” Note that the data set contained several observations with missing values, which we removed above to simplify the demonstration of our analytic methods. In practice, we recommend instead using appropriate corrections (e.g., imputation, inverse weighting) to fully take advantage of the observed data.\nFollowing the motivation of the original study, we focus on the causal effects of participating in a sports team (sports_2) on the BMI of children (bmi), taking into consideration several mediators (snack_2, exercises); c(\"age\", \"sex_F\", \"tvhours\") are taken to be potential baseline confounders.\nThe data on a single observational unit can be represented \\(O = (W, A, M, Y)\\), with the data pooled across all participants denoted \\(O_1, \\ldots, O_n\\), for a of \\(n\\) i.i.d. observations of \\(O\\). Recall the DAG from an earlier chapter, which represents the data-generating process:\nCode\\dimendef\\prevdepth=0\n\\pgfdeclarelayer{background}\n\\pgfsetlayers{background,main}\n\\usetikzlibrary{arrows,positioning}\n\\tikzset{\n&gt;=stealth',\npunkt/.style={\nrectangle,\nrounded corners,\ndraw=black, very thick,\ntext width=6.5em,\nminimum height=2em,\ntext centered},\npil/.style={\n-&gt;,\nthick,\nshorten &lt;=2pt,\nshorten &gt;=2pt,}\n}\n\\newcommand{\\Vertex}[2]\n{\\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\VertexR}[2]\n{\\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\ArrowR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend right=30] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\ArrowL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend right=-45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\Arrow}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) -- +(#2);\n\\end{pgfonlayer}\n}\n\\begin{tikzpicture}\n  \\Vertex{-4, 0}{W}\n  \\Vertex{0, 0}{M}\n  \\Vertex{-2, 0}{A}\n  \\Vertex{2, 0}{Y}\n  \\Arrow{W}{A}{black}\n  \\Arrow{A}{M}{black}\n  \\Arrow{M}{Y}{black}\n  \\ArrowL{W}{Y}{black}\n  \\ArrowL{A}{Y}{black}\n  \\ArrowL{W}{M}{black}\n\\end{tikzpicture}\n\n\n\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>`R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_walkthrough.html#crumble-flexible-and-general-mediation-analysis",
    "href": "chapters/estimation_walkthrough.html#crumble-flexible-and-general-mediation-analysis",
    "title": "\n6  R packages for estimation of the causal (in)direct effects\n",
    "section": "",
    "text": "crumble implements a one-step estimator of the natural, interventional, and organic (in)direct effect, as well as path-specific effects using recanting twins.\nThe estimator is capable of accommodating flexible modeling strategies (e.g., ensemble machine learning) for the initial estimation of nuisance parameters.\nTo this end, crumble integrates with the mlr3superlearner R package.\nThe estimator uses cross-fitting of nuisance parameters.\n\n\n\n\nIn crumble(), \\(A\\) is denoted trt, \\(Y\\) is denoted outcome, \\(M\\) is denoted mediators, and \\(W\\) is denoted covar.",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>`R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_walkthrough.html#estimating-nuisance-parameters",
    "href": "chapters/estimation_walkthrough.html#estimating-nuisance-parameters",
    "title": "\n6  R packages for estimation of the causal (in)direct effects\n",
    "section": "\n6.2 Estimating nuisance parameters",
    "text": "6.2 Estimating nuisance parameters\n\nRecall that the one-step estimator can be thought of as a combination of a weighted estimator and a regression estimator.\nWe’d like to rely on flexible, data adaptive strategies for nuisance parameter estimation.\nDoing so minimizes opportunities for model mis-specification to compromise our analytic conclusions.\n\n\n6.2.1 Super learning\n\nFor the regression function parts of the EIF (e.g., \\(\\E[Y\\mid A,M,W]\\)), crumble uses the Super Learner algorithm for ensemble machine learning (van der Laan, Polley, and Hubbard 2007), which is implemented in the mlr3superlearner R package.\nBelow, we demonstrate the construction of an ensemble learner based on a limited library of algorithms, including an intercept model, a main terms GLM, LASSO (\\(\\ell_1\\)-penalized) regression, and random forest (ranger).\n\n\nvan der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” Statistical Applications in Genetics and Molecular Biology 6 (1).\n\nensemble &lt;- list(\n  \"mean\",\n  \"glm\",\n  \"cv_glmnet\",\n  list(\"ranger\", num.trees = 200)\n)\n\n\nOf course, there are many alternatives for learning algorithms to be included in such a modeling library. Feel free to explore!\n\n6.2.2 Riesz representers\nIn a subset of the semi-parametric and double-machine learning literature, the weights in the EIF are sometimes referred to as Riesz representers. To understand why, let’s imagine that we want to estimate the total effect (i.e., the ATE) of a binary treatment \\(A\\) on some outcome \\(Y\\) accounting for confounders \\(W\\). Under standard identification assumptions, this effect is identified from the observed data as\n\\[\n\\psi = \\E[\\E[Y\\mid A= 1,W] - \\E[Y\\mid A= 0,W]]\\text{.}\n\\]\nLet’s denote \\(Q(a,W) = \\E[Y\\mid A=a,W]\\) and \\(m(O;Q)\\) as a continuous linear mapping of \\(Q(a,W)\\) and the observed data. In the case of the total effect, \\(m(O;Q) = Q(1,W) - Q(0,W)\\). We can then re-write the total effect as\n\\[\n\\E[m(O;Q)]\\text{.}\n\\]\nNow, consider that the total effect can equivalently be identified as\n\\[\n\\E\\bigg[\\bigg\\{\\frac{\\I(A=1)}{\\P(A=1 \\mid W)} - \\frac{\\I(A=0)}{1 - \\P(A=1 \\mid\nW)}\\bigg\\}Y \\bigg]\\text{.}\n\\]\nLet’s denote \\(\\frac{\\I(A=1)}{\\P(A=1 \\mid W)} - \\frac{\\I(A=0)}{1 - \\P(A=1 \\mid\nW)}\\) as \\(\\alpha_0(W)\\). Then,\n\\[\n\\E[m(O;Q)] = \\E[\\alpha_0(W) \\cdot Y]\\text{.}\n\\]\nAccording to the Riesz representation theorem, if \\(m(O;Q)\\) is a continuous linear functional of \\(Q\\) (which it is), then there exists a unique function \\(\\alpha_0(W)\\)–the so-called Riesz representer–such that\n\\[\n\\E[m(O;Q)] = \\E[\\alpha_0(W) \\cdot Q(A,W)]\\text{.}\n\\]\nUsing the tower rule, we have\n\\[\n\\begin{align*}\n\\E[m(O;Q)] &= \\E[\\alpha_0(W) \\cdot Y]\\\\\n&= \\E\\big[\\E[\\alpha_0(W) \\cdot Y\\mid A,W]\\big] \\\\\n&= \\E\\big[\\alpha_0(W) \\cdot \\E[Y\\mid A,W]\\big] \\\\\n& = \\E[\\alpha_0(W) \\cdot Q(A,W)]\\text{.}\n\\end{align*}\n\\]\nThus, \\(\\frac{\\I(A=1)}{\\P(A=1 \\mid W)} - \\frac{\\I(A=0)}{1 - \\P(A=1 \\mid W)}\\) is the Riesz representer for estimating the total effect of \\(A\\) on \\(Y\\)!\nWhile \\(\\alpha_0(W)\\) for the total effect has a nice close-form solution that can be easily estimated with off-the-shelf software, this isn’t always the case. With that in mind, Chernozhukov et al. (2021) showed that the Riesz representer is the minimizer of the the so-called Riesz loss:\n\nChernozhukov, Victor, Whitney K Newey, Victor Quintas-Martinez, and Vasilis Syrgkanis. 2021. “Automatic Debiased Machine Learning via Riesz Regression.” arXiv Preprint arXiv:2104.14737.\n\\[\n\\text{arg min}_\\alpha \\E[\\alpha_0(W)^2 - 2\\cdot m(O;\\alpha)]\\text{.}\n\\]\nThis means that we can directly estimate \\(\\alpha_0(W)\\) by minimizing the above loss function! For the case of mediation analysis, the methods we proposed in Liu et al. (2024) and implemented in crumble estimate Riesz representers of the type:\n\nLiu, Richard, Nicholas T Williams, Kara E Rudolph, and Iván Dı́az. 2024. “General Targeted Machine Learning for Modern Causal Mediation Analysis.” arXiv Preprint arXiv:2408.14620.\n\\[\n\\frac{\\I(A_i=1)}{\\hat{\\P}(A_i=1 \\mid W_i)}\n      \\frac{\\hat{\\P}(M_i \\mid A_i=0,W)_i}{\\hat{\\P}(M_i \\mid A_i=1,W_i)} -\n      \\frac{\\I(A=0)}{\\hat{\\P}(A_i=0 \\mid W_i)}\\text{.}\n\\]\ncrumble estimates this value (and others) for mediational effects directly by minimizing the Riesz loss with deep learning using torch. Much of this is abstracted away from the analyst, but we still need to specify some type of deep-learning architecture to use crumble. Here’s an example of a simple multilayer perceptron (MLP) with two hidden layers, each with 10 units, and a dropout rate of 0.1 which we create using the sequential_module() function from crumble.\n\nmlp &lt;- sequential_module(layers = 2, hidden = 10, dropout = 0.1)",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>`R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_walkthrough.html#efficient-estimation-of-the-natural-indirect-effects",
    "href": "chapters/estimation_walkthrough.html#efficient-estimation-of-the-natural-indirect-effects",
    "title": "\n6  R packages for estimation of the causal (in)direct effects\n",
    "section": "\n6.3 Efficient estimation of the natural (in)direct effects",
    "text": "6.3 Efficient estimation of the natural (in)direct effects\nTo start, we will consider estimation of the natural direct and indirect effects, which, we recall, are defined as follows\n\\[\n  \\E[Y_{1,M_1} - Y_{0,M_0}] =\n    \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{M_1}} -\n    Y_{\\color{red}{1},\\color{blue}{M_0}}]}_{\\text{natural indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{M_0}} -\n    Y_{\\color{blue}{0},\\color{red}{M_0}}]}_{\\text{natural direct effect}}.\n\\]\nLet’s use the crumble() function to estimate the natural direct and indirect effect.\n\nWe’ll use the ensemble of the intercept model, a main terms GLM, LASSO (\\(\\ell_1\\)-penalized) regression, and random forest we defined above (ensemble) for the regression parameters\nWe’ll use the multilayer perceptron we defined above (mlp) to estimate the Riesz representers.\nTo indicate we want to estimate the natural (in)direct effects, we set effect = \"N\".\n\ncrumble was designed to also work with continuous exposures. Because of this, we need to specify the treatment regimes to create the contrasts for the (in)direct effects.\n\n\nd0 and d1 are functions that return the treatment assignment under the two regimes. In our case, we want to estimate the effect of participating in a sports team, so we set d0 to always return 1 (i.e., no participation) and d1 to always return 0 (i.e., participation).\nWant to learn more about specifying causal effects using these d functions? Check out the workshop, Beyond the ATE happening after this one!\n\n\n\n\n# compute one-step estimates of the natural effects\ncrumble(\n  data = weight_behavior,\n  trt = \"sports_2\",\n  outcome = \"bmi\",\n  covar = c(\"age\", \"sex_F\", \"tvhours\"),\n  mediators = c(\"snack_2\", \"exercises\"),\n  d0 = function(data, trt) rep(1, nrow(data)),\n  d1 = function(data, trt) rep(0, nrow(data)),\n  effect = \"N\",\n  learners = ensemble,\n  nn_module = mlp,\n  control = crumble_control(crossfit_folds = 1L, epochs = 10L, learning_rate = 0.01)\n)\n# ✔ Fitting outcome regressions... 1/1 folds [5.4s]\n# ✔ Computing alpha n density ratios... 1/1 folds [7s]\n#\n# ══ Results `crumble()` ════════════════════════════════════════════════════════════════\n#\n# ── Direct Effect\n#       Estimate: -1.08\n#     Std. error: 0.26\n# 95% Conf. int.: -1.6, -0.57\n#\n# ── Indirect Effect\n#       Estimate: 0.06\n#     Std. error: 0.05\n# 95% Conf. int.: -0.05, 0.16\n#\n# ── Average Treatment Effect\n#       Estimate: -1.03\n#     Std. error: 0.3\n# 95% Conf. int.: -1.61, -0.44",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>`R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "chapters/estimation_walkthrough.html#efficient-estimation-of-the-interventional-indirect-effects",
    "href": "chapters/estimation_walkthrough.html#efficient-estimation-of-the-interventional-indirect-effects",
    "title": "\n6  R packages for estimation of the causal (in)direct effects\n",
    "section": "\n6.4 Efficient estimation of the interventional (in)direct effects",
    "text": "6.4 Efficient estimation of the interventional (in)direct effects\nSince our knowledge of the system under study is incomplete, we might worry that one (or more) of the measured variables are not mediators, but, in fact, intermediate confounders affected by treatment. While the natural (in)direct effects are not identified in this setting, their interventional (in)direct counterparts are, as we saw in an earlier section. Recall that both types of effects are defined by static interventions on the treatment. The interventional effects are distinguished by their use of a stochastic intervention on the mediator to aid in their identification.\n\nCode\\dimendef\\prevdepth=0\n\\pgfdeclarelayer{background}\n\\pgfsetlayers{background,main}\n\\usetikzlibrary{arrows,positioning}\n\\tikzset{\n&gt;=stealth',\npunkt/.style={\nrectangle,\nrounded corners,\ndraw=black, very thick,\ntext width=6.5em,\nminimum height=2em,\ntext centered},\npil/.style={\n-&gt;,\nthick,\nshorten &lt;=2pt,\nshorten &gt;=2pt,}\n}\n\\newcommand{\\Vertex}[2]\n{\\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\VertexR}[2]\n{\\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\ArrowR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend right=30] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\ArrowL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend right=-45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\Arrow}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) -- +(#2);\n\\end{pgfonlayer}\n}\n\\begin{tikzpicture}\n  \\Vertex{0, -1}{Z}\n  \\Vertex{-4, 0}{W}\n  \\Vertex{0, 0}{M}\n  \\Vertex{-2, 0}{A}\n  \\Vertex{2, 0}{Y}\n  \\ArrowR{W}{Z}{black}\n  \\Arrow{Z}{M}{black}\n  \\Arrow{W}{A}{black}\n  \\Arrow{A}{M}{black}\n  \\Arrow{M}{Y}{black}\n  \\Arrow{A}{Z}{black}\n  \\Arrow{Z}{Y}{black}\n  \\ArrowL{W}{Y}{black}\n  \\ArrowL{A}{Y}{black}\n  \\ArrowL{W}{M}{black}\n\\end{tikzpicture}\n\n\n\nDirected acyclic graph under intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\nRecall that the interventional (in)direct effects are defined via the decomposition:\n\\[\n  \\E[Y_{1,G_1} - Y_{0,G_0}] =\n    \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{G_1}} -\n    Y_{\\color{red}{1},\\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n    Y_{\\color{blue}{0},\\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\]\n\nIn our data example, we’ll consider the eating of snacks as a potential intermediate confounder, since one might reasonably hypothesize that participation on a sports team might subsequently affect snacking, which then could affect mediators like the amount of exercises and overweight status.\n\nWe can easily estimate the interventional direct and indirect effects by setting effect = \"RI\" and specifying the intermediate confounders in the moc argument.\n\n\n# compute one-step estimates of the interventional effects\ncrumble(\n  data = weight_behavior,\n  trt = \"sports_2\",\n  outcome = \"bmi\",\n  covar = c(\"age\", \"sex_F\", \"tvhours\"),\n  mediators = \"exercises\",\n  moc = \"snack_2\",\n  d0 = function(data, trt) rep(1, nrow(data)),\n  d1 = function(data, trt) rep(0, nrow(data)),\n  effect = \"RI\",\n  learners = ensemble,\n  nn_module = mlp,\n  control = crumble_control(crossfit_folds = 1L, epochs = 10L, learning_rate = 0.01)\n)\n# ✔ Permuting Z-prime variables... 1/1 tasks [1.3s]\n# ✔ Fitting outcome regressions... 1/1 folds [7.1s]\n# ✔ Computing alpha r density ratios... 1/1 folds [13.3s]\n#\n# ══ Results `crumble()` ════════════════════════════════════════════════════════════════\n#\n# ── Randomized Direct Effect\n#       Estimate: -1.12\n#     Std. error: 0.43\n# 95% Conf. int.: -1.97, -0.27\n#\n# ── Randomized Indirect Effect\n#       Estimate: 0\n#     Std. error: 0.03\n# 95% Conf. int.: -0.05, 0.05",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>`R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chernozhukov, Victor, Whitney K Newey, Victor Quintas-Martinez, and\nVasilis Syrgkanis. 2021. “Automatic Debiased Machine Learning via\nRiesz Regression.” arXiv Preprint arXiv:2104.14737.\n\n\nDı́az, Iván, and Nima S Hejazi. 2020. “Causal Mediation Analysis\nfor Stochastic Interventions.” Journal of the Royal\nStatistical Society: Series B (Statistical Methodology) 82 (3):\n661–83.\n\n\nHejazi, Nima S, Kara E Rudolph, Mark J van der Laan, and Iván Dı́az.\n2022. “Nonparametric Causal Mediation Analysis for Stochastic\nInterventional (in) Direct Effects.” Biostatistics (in\npress). https://doi.org/10.1093/biostatistics/kxac002.\n\n\nKennedy, Edward H. 2018. “Nonparametric Causal Effects Based on\nIncremental Propensity Score Interventions.” Journal of the\nAmerican Statistical Association, no. just-accepted.\n\n\nLiu, Richard, Nicholas T Williams, Kara E Rudolph, and Iván Dı́az. 2024.\n“General Targeted Machine Learning for Modern Causal Mediation\nAnalysis.” arXiv Preprint arXiv:2408.14620.\n\n\nMiles, Caleb H. 2022. “On the Causal Interpretation of Randomized\nInterventional Indirect Effects.” arXiv Preprint\narXiv:2203.00245. https://arxiv.org/abs/2203.00245.\n\n\nRudolph, Kara E, Shodai Inose, Nicholas T Williams, Katherine L Hoffman,\nSarah E Forrest, Rachael K Ross, Floriana Milazzo, et al. 2025.\n“Mediation of Chronic Pain and Disability on Opioid Use Disorder\nRisk by Pain Management Practices Among Adult Medicaid Patients,\n2016-2019.” American Journal of Epidemiology, kwaf093.\n\n\nTchetgen Tchetgen, Eric J, and Tyler J VanderWeele. 2014. “On\nIdentification of Natural Direct Effects When a Confounder of the\nMediator Is Directly Affected by Exposure.” Epidemiology\n25 (2): 282.\n\n\nvan der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007.\n“Super Learner.” Statistical Applications\nin Genetics and Molecular Biology 6 (1).\n\n\nVo, Tat-Thang, Nicholas Williams, Richard Liu, Kara E Rudolph, and Ivan\nDıaz. 2024. “Recanting Twins: Addressing Intermediate Confounding\nin Mediation Analysis.” arXiv Preprint arXiv:2401.04450.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "chapters/additional_readings.html",
    "href": "chapters/additional_readings.html",
    "title": "7  Appendix: Additional topics of interest",
    "section": "",
    "text": "7.1 Mediation with multiple mediators and multiple intermediate confounders\nThe literature on mediation analysis has grown considerably in the last few decades and there are now many novel methods to tackle important questions with complex data structures. While we are unable to cover all these interesting methods in this workshop, here we provide a few references for further reading.\nThis list is not meant to be comprehensive, just some of our own work and some work by others that we know and consider interesting.\nNote that the medoutcon R package works for multiple mediators but is limited to settings with only a single, binary intermediate confounder. If your data scenario includes multiple mediators and multiple intermediate confounders, you should consider using the HDmediation R package instead.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "chapters/additional_readings.html#mediation-with-multiple-mediators-and-multiple-intermediate-confounders",
    "href": "chapters/additional_readings.html#mediation-with-multiple-mediators-and-multiple-intermediate-confounders",
    "title": "7  Appendix: Additional topics of interest",
    "section": "",
    "text": "Practical causal mediation analysis: extending nonparametric estimators to estimate the mediated effects of housing voucher receipt on adolescent risk behavior By Kara E. Rudolph, Nicholas Williams, and Iván Díaz",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "chapters/additional_readings.html#mediation-with-monotonicity-of-a-z-relationship",
    "href": "chapters/additional_readings.html#mediation-with-monotonicity-of-a-z-relationship",
    "title": "7  Appendix: Additional topics of interest",
    "section": "7.2 Mediation with monotonicity of A-Z relationship",
    "text": "7.2 Mediation with monotonicity of A-Z relationship\n\nOn identification of natural direct effects when a confounder of the mediator is directly affected by exposure by Eric J. Tchetgen Tchetgen and Tyler J. VanderWeele\nEfficient and flexible estimation of natural mediation effects under intermediate confounding and monotonicity constraints by Kara E. Rudolph and Iván Díaz",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "chapters/additional_readings.html#mediation-with-instrumental-variables",
    "href": "chapters/additional_readings.html#mediation-with-instrumental-variables",
    "title": "7  Appendix: Additional topics of interest",
    "section": "7.3 Mediation with instrumental variables",
    "text": "7.3 Mediation with instrumental variables\n\nDirect and indirect treatment effects–causal chains and mediation analysis with instrumental variables by Markus Frolich and Martin Huber\nCausal mediation with instrumental variables by Kara E. Rudolph, Nicholas Williams, and Iván Díaz",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "chapters/additional_readings.html#mediation-with-separable-effects",
    "href": "chapters/additional_readings.html#mediation-with-separable-effects",
    "title": "7  Appendix: Additional topics of interest",
    "section": "7.4 Mediation with separable effects",
    "text": "7.4 Mediation with separable effects\n\nAn Interventionist Approach to Mediation Analysis by James M. Robins, Thomas S. Richardson, and Ilya Shpitser\nConditional Separable Effects by Mats J. Stensrud, James M. Robins, Aaron Sarvet, Eric J. Tchetgen Tchetgen, and Jessica G. Young\nSeparable Effects for Causal Inference in the Presence of Competing Events by Mats J. Stensrud, Jessica G. Young, Vanessa Didelez, James M. Robins, and Miguel A. Hernán\nA Generalized Theory of Separable Effects in Competing Event Settings by Mats J. Stensrud, Miguel A. Hernán, Eric J. Tchetgen Tchetgen, James M. Robins, Vanessa Didelez, and Jessica G. Young",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "chapters/stochastic_effects.html",
    "href": "chapters/stochastic_effects.html",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "",
    "text": "8.1 Definition of the effects\nConsider the following directed acyclic graph.\nCode\\dimendef\\prevdepth=0\n\\pgfdeclarelayer{background}\n\\pgfsetlayers{background,main}\n\\usetikzlibrary{arrows,positioning}\n\\tikzset{\n&gt;=stealth',\npunkt/.style={\nrectangle,\nrounded corners,\ndraw=black, very thick,\ntext width=6.5em,\nminimum height=2em,\ntext centered},\npil/.style={\n-&gt;,\nthick,\nshorten &lt;=2pt,\nshorten &gt;=2pt,}\n}\n\\newcommand{\\Vertex}[2]\n{\\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\VertexR}[2]\n{\\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};\n}\n\\newcommand{\\ArrowR}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend right=30] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\ArrowL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) to[bend left=45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\EdgeL}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[dashed,#3] (#1) to[bend right=-45] (#2);\n\\end{pgfonlayer}\n}\n\\newcommand{\\Arrow}[3]\n{ \\begin{pgfonlayer}{background}\n\\draw[-&gt;,#3] (#1) -- +(#2);\n\\end{pgfonlayer}\n}\n\\begin{tikzpicture}\n  \\Vertex{-4, 0}{W}\n  \\Vertex{0, 0}{M}\n  \\Vertex{-2, 0}{A}\n  \\Vertex{2, 0}{Y}\n  \\Arrow{W}{A}{black}\n  \\Arrow{A}{M}{black}\n  \\Arrow{M}{Y}{black}\n  \\ArrowL{W}{Y}{black}\n  \\ArrowL{A}{Y}{black}\n  \\ArrowL{W}{M}{black}\n\\end{tikzpicture}\n\n\n\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "chapters/stochastic_effects.html#motivation-for-stochastic-interventions",
    "href": "chapters/stochastic_effects.html#motivation-for-stochastic-interventions",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.2 Motivation for stochastic interventions",
    "text": "8.2 Motivation for stochastic interventions\n\nSo far we have discussed controlled, natural, and interventional (in)direct effects\nThese effects require that \\(0 &lt; \\P(A=1\\mid W) &lt; 1\\)\n\nThey are defined only for binary exposures\nWhat can we do when the positivity assumption does not hold or the exposure is continuous?\nSolution: We can use stochastic effects",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "chapters/stochastic_effects.html#definition-of-stochastic-effects",
    "href": "chapters/stochastic_effects.html#definition-of-stochastic-effects",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.3 Definition of stochastic effects",
    "text": "8.3 Definition of stochastic effects\nThere are two possible ways of defining stochastic effects:\n\nConsider the effect of an intervention where the exposure is drawn from a distribution\n\nFor example incremental propensity score interventions\n\n\nConsider the effect of an intervention where the post-intervention exposure is a function of the actually received exposure\n\nFor example modified treatment policies\n\n\nIn both cases \\(A \\mid W\\) is a non-deterministic intervention, thus the name stochastic intervention\n\n\n\n8.3.1 Example: incremental propensity score interventions (IPSI) (Kennedy 2018)\n\n\nKennedy, Edward H. 2018. “Nonparametric Causal Effects Based on Incremental Propensity Score Interventions.” Journal of the American Statistical Association, no. just-accepted.\nDefinition of the intervention\n\nAssume \\(A\\) is binary, and \\(\\P(A=1\\mid W=w) = g(1\\mid w)\\) is the propensity score\nConsider an intervention in which each individual receives the intervention with probability \\(g_\\delta(1\\mid w)\\), equal to \\[\\begin{equation*}\n  g_\\delta(1\\mid w)=\\frac{\\delta g(1\\mid w)}{\\delta g(1\\mid w) +\n  1 - g(1\\mid w)}\n\\end{equation*}\\]\n\ne.g., draw the post-intervention exposure from a Bernoulli variable with probability \\(g_\\delta(1\\mid w)\\)\n\nThe value \\(\\delta\\) is user given\nLet \\(A_\\delta\\) denote the post-intervention exposure distribution\nSome algebra shows that \\(\\delta\\) is an odds ratio comparing the pre- and post-intervention exposure distributions \\[\\begin{equation*}\n  \\delta = \\frac{\\text{odds}(A_\\delta = 1\\mid W=w)}\n  {\\text{odds}(A = 1\\mid W=w)}\n\\end{equation*}\\]\n\nInterpretation: what would happen in a world where the odds of receiving treatment is increased by \\(\\delta\\)\n\nLet \\(Y_{A_\\delta}\\) denote the outcome in this hypothetical world\n\n8.3.1.1 Illustrative application for IPSIs\n\nConsider the effect of participation in sports on children’s BMI\nMediation through snacking, exercising, etc.\nIntervention: for each individual, increase the odds of participating in sports by \\(\\delta=2\\)\n\nThe post-intervention exposure is a draw \\(A_\\delta\\) from a Bernoulli distribution with probability \\(g_\\delta(1\\mid w)\\)\n\nExample: modified treatment policies (MTP) (Dı́az and Hejazi 2020)\n\n\nDı́az, Iván, and Nima S Hejazi. 2020. “Causal Mediation Analysis for Stochastic Interventions.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 82 (3): 661–83.\nDefinition of the intervention\n\nConsider a continuous exposure \\(A\\) taking values in the real numbers\nConsider an intervention that assigns exposure as \\(A_\\delta = A - \\delta\\)\n\nExample: \\(A\\) is pollution measured as \\(PM_{2.5}\\) and you are interested in an intervention that reduces \\(PM_{2.5}\\) concentration by some amount \\(\\delta\\)\n\n\n8.3.2 Mediation analysis for stochastic interventions\n\nThe total effect of an IPSI can be computed as a contrast of the outcome under intervention vs no intervention: \\[\\begin{equation*}\n  \\psi = \\E[Y_{A_\\delta} - Y]\n\\end{equation*}\\]\nRecall the NPSEM \\[\\begin{align*}\n  W & = f_W(U_W)\\\\\n  A & = f_A(W, U_A)\\\\\n  M & = f_M(W, A, U_M)\\\\\n  Y & = f_Y(W, A, M, U_Y)\n\\end{align*}\\]\nFrom this we have \\[\\begin{align*}\nM_{A_\\delta} & = f_M(W, A_\\delta, U_M)\\\\\nY_{A_\\delta} & = f_Y(W, A_\\delta, M_{A_\\delta}, U_Y)\n\\end{align*}\\]\nThus, we have \\(Y_{A_\\delta} = Y_{A_\\delta, M_{A_\\delta}}\\) and \\(Y =\nY_{A,M_{A}}\\)\nLet us introduce the counterfactual \\(Y_{A_\\delta, M}\\), interpreted as the outcome observed in a world where the intervention on \\(A\\) is performed but the mediator is fixed at the value it would have taken under no intervention: [Y_{A_, M} = f_Y(W, A_, M, U_Y)]\nThen we can decompose the total effect into: \\[\\begin{align*}\n  \\E[Y&_{A_\\delta,M_{A_\\delta}} - Y_{A,M_A}] = \\\\\n  &\\underbrace{\\E[Y_{\\color{red}{A_\\delta},\\color{blue}{M_{A_\\delta}}} -\n    Y_{\\color{red}{A_\\delta},\\color{blue}{M}}]}_{\\text{stochastic natural\n      indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{A_\\delta},\\color{red}{M}} -\n    Y_{\\color{blue}{A},\\color{red}{M}}]}_{\\text{stochastic natural direct\n      effect}}\n\\end{align*}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "chapters/stochastic_effects.html#identification-assumptions",
    "href": "chapters/stochastic_effects.html#identification-assumptions",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.4 Identification assumptions",
    "text": "8.4 Identification assumptions\n\nConfounder assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\n\nNo confounder of \\(M\\rightarrow Y\\) affected by \\(A\\)\n\nPositivity assumptions:\n\nIf \\(g_\\delta(a \\mid w)&gt;0\\) then \\(g(a \\mid w)&gt;0\\)\n\nIf \\(\\P(M=m\\mid W=w)&gt;0\\) then \\(\\P(M=m\\mid A=a,W=w)&gt;0\\)\n\n\n\n\nUnder these assumptions, stochastic effects are identified as follows\n\nThe indirect effect can be identified as follows \\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, W)\n  -\\E(Y\\mid A=a, M, W)\\}}g_\\delta(a\\mid W)}\\right]\n\\end{align*}\\]\nThe direct effect can be identified as follows \\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, M, W)\n  - Y\\}}g_\\delta(a\\mid W)}\\right]\n\\end{align*}\\]\n\nLet’s dissect the formula for the indirect effect in R:\n\nCoden &lt;- 1e6\nw &lt;- rnorm(n)\na &lt;- rbinom(n, 1, plogis(1 + w))\nm &lt;- rnorm(n, w + a)\ny &lt;- rnorm(n, w + a + m)\n\n\n\n\nFirst, fit regressions of the outcome on \\((A,W)\\) and \\((M,A,W)\\):\n\nCodefit_y1 &lt;- lm(y ~ m + a + w)\nfit_y2 &lt;- lm(y ~ a + w)\n\n\n\n\nGet predictions fixing \\(A=a\\) for all possible values \\(a\\)\n\nCodepred_y1_a1 &lt;- predict(fit_y1, newdata = data.frame(a = 1, m, w))\npred_y1_a0 &lt;- predict(fit_y1, newdata = data.frame(a = 0, m, w))\npred_y2_a1 &lt;- predict(fit_y2, newdata = data.frame(a = 1, w))\npred_y2_a0 &lt;- predict(fit_y2, newdata = data.frame(a = 0, w))\n\n\n\n\nCompute [] for each value \\(a\\)\n\nCodepseudo_a1 &lt;- pred_y2_a1 - pred_y1_a1\npseudo_a0 &lt;- pred_y2_a0 - pred_y1_a0\n\n\n\n\nEstimate the propensity score \\(g(1\\mid w)\\) and evaluate the post-intervention propensity score \\(g_\\delta(1\\mid w)\\)\n\nCodepscore_fit &lt;- glm(a ~ w, family = binomial())\npscore &lt;- predict(pscore_fit, type = \"response\")\n## How do the intervention vs observed propensity score compare\npscore_delta &lt;- 2 * pscore / (2 * pscore + 1 - pscore)\n\n\n\n\nWhat do the post-intervention propensity scores look like?\n\nCodeplot(pscore, pscore_delta,\nxlab = \"Observed prop. score\",\nylab = \"Prop. score under intervention\"\n)\nabline(0, 1)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "chapters/stochastic_effects.html#what-are-the-odds-of-exposure-under-intervention-vs-real-world",
    "href": "chapters/stochastic_effects.html#what-are-the-odds-of-exposure-under-intervention-vs-real-world",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.5 What are the odds of exposure under intervention vs real world?",
    "text": "8.5 What are the odds of exposure under intervention vs real world?\n\nCodeodds &lt;- (pscore_delta / (1 - pscore_delta)) / (pscore / (1 - pscore))\nsummary(odds)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      2       2       2       2       2       2 \n\n\n\n\nCompute the sum \\[\\begin{equation*}\n  \\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, W) -\n    \\E(Y\\mid A=a, M, W)\\}}g_\\delta(a\\mid W)}\n\\end{equation*}\\]\n\nCodeindirect &lt;- pseudo_a1 * pscore_delta + pseudo_a0 * (1 - pscore_delta)\n\n\n\n\nThe average of this value is the indirect effect\n\nCode## E[Y(Adelta) - Y(Adelta, M)]\nmean(indirect)\n\n[1] 0.1089619\n\n\n\nThe direct effect is \\[\\begin{align*}\n  \\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n  &\\E\\left[\\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, M,\n    W) - Y\\}}g_\\delta(a\\mid W)}\\right]\n\\end{align*}\\]\n\nWhich can be computed as\n\nCodedirect &lt;- (pred_y1_a1 - y) * pscore_delta +\n(pred_y1_a0 - y) * (1 - pscore_delta)\nmean(direct)\n\n[1] 0.109599",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "chapters/stochastic_effects.html#summary",
    "href": "chapters/stochastic_effects.html#summary",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.6 Summary",
    "text": "8.6 Summary\n\nStochastic (in)direct effects\n\nRelax the positivity assumption\nCan be defined for non-binary exposures\nDo not require a cross-world assumption\n\n\nStill require the absence of intermediate confounders\n\nBut, compared to the NDE and NIE, we can design a randomized study where identifiability assumptions hold, at least in principle\nThere is a version of these effects that can accommodate intermediate confounders (Hejazi et al. 2022)\n\n\nR implementation to be released soon…stay tuned!\n\n\n\n\n\n\n\n\nHejazi, Nima S, Kara E Rudolph, Mark J van der Laan, and Iván Dı́az. 2022. “Nonparametric Causal Mediation Analysis for Stochastic Interventional (in) Direct Effects.” Biostatistics (in press). https://doi.org/10.1093/biostatistics/kxac002.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  }
]